```{r include=FALSE}
source("R/common.R")
```

# Plots of Multivariate Data {#sec-multivariate_plots}

> There is no excuse for failing to plot and look.
--- J. W.Tukey (1997), _Exploratory Data Analysis_, p. 157


The quote above from John Tukey reminds us that data analysis should rightly start with
graphs to help us understand the main features of our data, to see patterns, trends
and anomalies. 
This chapter introduces a toolbox of basic graphical methods for visualizing multivariate datasets. It starts with some simple techniques to enhance the basic scatterplot with annotations such as fitted lines, curves and data ellipses to summarize the relation between two variables. 

To visualize more than two variables, we can view all pairs of variables in a scatterplot matrix or shift gears entirely to show multiple variables along a set of parallel axes. As the number of variables increase, we may need to suppress details with stronger summaries for a high-level reconnaissance of our data terrain, as we do by zooming out on a map.

Topics (just for reference)

-   Bivariate summaries
    -   smoothers
    -   data ellipses
-   Quantitative data:
    -   scatterplot matrices
    -   parallel coordinate plots
-   ~~Categorical data:~~
    -   ~~mosaic plots~~
-   Generalized pair plots

**Packages**

In this chapter we use the following packages. Load them now:
```{r load-pkgs}
library(car)
library(ggplot2)
library(dplyr)
library(tidyr)
library(corrgram)
```

## Bivariate summaries {#sec-bivariate_summaries}


The basic scatterplot is the workhorse of multivariate data visualization, showing
how one variable, $y$, often an outcome to be explained varies with another, $x$.
It is a building block for many useful techniques, so it is helpful to understand
how it can be used as a tool for thinking in a wider, multivariate context.

An essential idea is that we can start with a simple version and add plot annotations
to show interesting features more clearly. We consider the following here:

  + **smoothers**: showing overall trends, perhaps several, as visual summaries
  + **stratifiers**: using color, shape or other features to identify subgroups; more generally, _conditioning_ on other variables;
  + **data ellipses**: a compact visual summary of linear relations and uncertainty.

Let's start with data on the academic salaries of faculty members
collected at a U.S. college for the purpose of assessing salary differences
between male and female faculty members, and perhaps address anomalies
in compensation.
The dataset `carData::Salaries`
gives data on nine-month salaries and other variables for 397 faculty members in the 2008-2009 academic year.

```{r Salaries}
data(Salaries, package = "carData")
str(Salaries)
```

The most obvious predictor of `salary` is `years.since.phd`; for simplicity, I'll refer to
this as years of "experience".
Before looking at differences
between males and females, we would want consider faculty `rank` (related also to `yrs.service`)
and `discipline`, recorded here as `A` (“theoretical” departments) or `B` (“applied” departments).

```{r}
#| label: fig-Salaries-scat
#| out-width: "80%"
#| fig-cap: "Scatterplot of Salary vs. years since PhD."
library(ggplot2)
gg1 <-ggplot(Salaries, 
       aes(x = yrs.since.phd, y = salary)) +
  geom_jitter(size = 2) +
  scale_y_continuous(labels = scales::dollar_format(
    prefix="$", scale = 0.001, suffix = "K")) +
  labs(x = "Years since PhD",
       y = "Salary") +
  theme_bw(base_size = 14) 
gg1
```

There is quite a lot we can see "just by looking" at this simple plot, but the main things are:

* salary increases generally from 0 - 40 years since the PhD; 
* variability in salary increases among those with the same experience, a "fan-shaped" pattern that signals a violation of homogeneity of variance in simple regression;
* data beyond 50 years is thin, but there are some quite low salaries there.

### Smoothers

Smoothers are among the most useful graphical annotations you can add to such plots,
giving a visual summary of how $y$ changes with $x$.
The most common is to add a line showing the linear regression predictor for
$y$ given $x$, expressed in math notation as $\mathbb{E} (y | x) = b_0 + b_1 x$.
If there is doubt that a linear relation is an adequate summary,
you can try a quadratic or other polynomial smoother.
In **ggplot2**, these are easily added to a plot using `geom_smooth()` with
`method = "lm"`, and a model `formula`, which is `y ~ x` for a linear relation
or `y ~ poly(x, k)` for a polynomial of degree $k$.

```{r}
#| label: fig-Salaries-lm
#| out-width: "80%"
#| fig-cap: "Scatterplot of Salary vs. years since PhD, showing linear and quadratic smooths with 95% confidence bands."
gg1 + 
  geom_smooth(method = "lm", formula = "y ~ x", 
              color = "red", fill= "red",
              linewidth = 2) +
  geom_smooth(method = "lm", formula = "y ~ poly(x,2)", 
              color = "darkgreen", fill = "darkgreen",
              linewidth = 2) 
```

This serves to highlight some of our impressions from the basic scatterplot shown in
@fig-Salaries-scat, making them more apparent. And that's precisely the point: The regression smoother draws attention to a possible pattern that we can consider as a visual summary of the data. You can think of this as showing what a linear (or quadratic) regression "sees" in the data.
Statistical tests (secref?) can help you decide if there is more evidence for a quadratic fit compared to the simpler linear relation.

It is useful to also show some indication of _uncertainty_ (or inversely, _precision_)
associated with with the predicted values.
Both the linear and quadratic trends are shown in @fig-Salaries-lm with 95% pointwise
confidence bands. These are necessarily narrower in the center of the range of $x$ where
there is typically more data; they get wider toward the highest values of experience
where the data are thin.

#### Non-parametric smoothers {.nonumber}

The most generally useful idea is a smoother that tracks an average value, $\mathbb{E} (y | x)$, of $y$ as $x$ varies across its' range without assuming any particular functional form, and so avoiding the necessity to choose among 
`y ~ poly(x, 1)`, or `y ~ poly(x, 2)`, or `y ~ poly(x, 3)` ...

Non-parametric smoothers attempt to estimate $\mathbb{E} (y | x) = f(x)$
where $f(x)$ is some smooth function, and typically use a collection of weighted
_local regressions_ for each $x_i$ within a window centered at that value.
In the method called _lowess_ or _loess_ [@Cleveland:79; @ClevelandDevlin:88],
a weight function is applied, giving greatest weight to $x_i$ and weights of
0 outside a window containing a fraction $s$ of the nearest neighbors of $x_i$.
The fraction, $s$, usually within the range $1/3 \le s \le 2/3$,
called the _span_, determines the smoothness of the
resulting curve, with larger values giving a smoother fit.
Non-parametric regression is broad topic;
see @Fox:2016:ARA, Ch. 18 for a more general treatment.

@fig-Salaries-loess shows the addition of a loess smooth to the plot in @fig-Salaries-lm,
suppressing the confidence band for the linear regression. The loess fit is nearly coincident
with the quadratic fit, but has a slightly wider confidence band.
```{r}
#| label: fig-Salaries-loess
#| out-width: "80%"
#| fig-cap: "Scatterplot of Salary vs. years since PhD, adding the loess smooth."
gg1 + 
  geom_smooth(method = "loess", formula = "y ~ x", 
              color = "blue", fill = scales::muted("blue"),
              linewidth = 2) +
  geom_smooth(method = "lm", formula = "y ~ x", se = FALSE,
              color = "red",
              linewidth = 2) +
  geom_smooth(method = "lm", formula = "y ~ poly(x,2)", 
              color = "darkgreen", fill = "lightgreen",
              linewidth = 2) 
```

But now comes an important question: Is it reasonable that academic salary should increase up to about 40 years since the PhD degree and then decline? The predicted salary for someone 
still working 50 years after earning their degree is about the same as a person at 15 years.
What else is going on here?

### Stratifiers

Very often, we have a main relationship of interest, but various groups in the data are identified by discrete factors (like faculty `rank` and `sex`, their type of `discipline` here), or there are
quantitative predictors (_moderators_) for which the main relation might vary. 

I call these _stratifiers_, recognizing that we should consider breaking down the overall relation
to see whether and how it changes over such "other" variables.  Such variables are most
often factors, but we can cut a continuous variable into ranges (_shingles_) and do the same.
There are two general stratifying graphical techniques:

* **grouping**: Identify subgroups in the data by assigning different visual attributes, such as color, shape, line style, etc. within a single plot. This is quite natural for factors; quantitative predictors can be accommodated by cutting their range into ordered intervals. Two such grouping variables can be 
Grouping has the advantage that the levels of a grouping variable can be shown within the same plot, facilitating direct comparison.

* **conditioning**: Showing subgroups in different plot panels. This has the advantages that relations for the individual groups more easily discerned and
one can easily stratify by two (or more) other variables jointly, but visual comparison
is more difficult because the eye must scan from one panel to another.

::: {.callout-note}
## A bit of history
Recognition of the roles of visual grouping by factors within a panel and conditioning in multi-panel displays was an important
advance in the development of modern statistical graphics. It began at 
A.T.&T. Bell Labs in Murray Hill, NJ in conjunction with the **S** language,
the mother of R.

Conditioning displays (originally called _coplots_ [@ChambersHastie1991]) are
simply a collection of 1D, 2D or 3D plots separate panels for subsets of the data broken down by one or more factors, or, for quantitative variables,
subdivided into a factor with several overlapping intervals (_shingles_).
The first implementation was in _Trellis_ plots
@Becker:1996:VDC; Cleveland:85.

Trellis displays were extended in the **lattice** package [@R-lattice], which offered:

* a **graphing syntax** similar to that used in statistical model formulas:
`y ~ x | g` conditions the data by the levels of `g`, with `|` read as "given";
two or more conditioning are specified as `y ~ x | g1 + g2 + ...`, with `+` read as "and".
* **panel functions** define what is plotted in a given panel. `panel.xyplot()` is the default for scatterplots, plotting points, but you can add `panel.lmline()` for regression lines, `latticeExtra::panel.smoother()` for loess smooths and a
wide variety of others.
:::

The most obvious variable that affects academic salary is `rank`, because faculty typically get an increase in salary with a promotion that carries through in their future salary. What can we see if we group by `rank` and fit a separate smoothed curve for each?

In `ggplot2` thinking, grouping is accomplished simply by adding an aesthetic, such as `color = rank`. 
what happens then is that points, lines, smooths and other `geom_*()` inherit the feature that they
are differentiated by color. In the case of `geom_smooth()`, we get a separate fit for each subset of
the data, according to `rank`.

```{r}
#| label: fig-Salaries-rank
#| out-width: "80%"
#| fig-cap: "Scatterplot of Salary vs. years since PhD, grouped by rank."
# make some re-useable pieces to avoid repetitions
scale_salary <-   scale_y_continuous(
  labels = scales::dollar_format(prefix="$", 
                                 scale = 0.001, 
                                 suffix = "K")) 
# position the legend inside the plot
legend_pos <- theme(legend.position = c(.1, 0.95), 
                    legend.justification = c(0, 1))

ggplot(Salaries, 
       aes(x = yrs.since.phd, y = salary, 
           color = rank)) +
  geom_point() +
  scale_salary +
  labs(x = "Years since PhD",
       y = "Salary") +
  geom_smooth(aes(fill = rank),
                  method = "loess", formula = "y ~ x", 
                  linewidth = 2) + 
#  theme_bw(base_size = 14) +
  legend_pos
```

Well, there is a different story here. Salaries generally occupy separate levels, increasing with academic rank. The horizontal extents of the smoothed curves show their ranges. Within each rank there is some initial increase after promotion, and then
some tendency to decline with increasing years. But by and large, years since the PhD doesn't make that much difference, once we've taken academic rank into account

What about the `discipline`, classified, perhaps peculiarly as "theoretical"
vs. "applied", here? The values are just `"A"` and `"B"`, so I map these to
more meaningful labels before making the plot.

```{r}
#| label: fig-Salaries-discipline
#| out-width: "80%"
#| fig-cap: "Scatterplot of Salary vs. years since PhD, grouped by discipline."
Salaries <- Salaries |>
  mutate(discipline = factor(discipline, 
                             labels = c("A: Theoretical", "B: Applied")))

Salaries |>
  ggplot(aes(x = yrs.since.phd, y = salary, color = discipline)) +
    geom_point() +
  scale_salary +
  geom_smooth(aes(fill = discipline ),
                method = "loess", formula = "y ~ x", 
                linewidth = 2) + 
  labs(x = "Years since PhD",
       y = "Salary") +
  legend_pos 
```

The story is again different. Faculty in applied disciplines on average, earn about
10,000$ more per year on average than their theoretical colleagues. 
```{r discipline-means}
Salaries |>
  group_by(discipline) |>
  summarize(mean = mean(salary)) 
```

For both groups, there is an approximately linear relation up to about 30--40 years, but the smoothed curves
then diverge, into the region where the data is thin.

### Conditioning

The previous plots use grouping by color to plot the data for different subsets inside the same plot window,
making comparison among groups easier, because they can be directly compared along a common vertical scale [^1].
This gets messy however when there are more than just a few levels, or worse---when there are two (or more)
variables for which we want to show separate effects. In such cases, we can plot separate panels using the `ggplot2`
concept of _faceting_. There are two options: `facet_wrap()` takes one or more
conditioning variables, produces plots for each combination of levels

[^1]: The classic study by @ClevelandMcGill:84b;@ClevelandMcGill:85 shows that judgements of magnitude along a common scale are more accurate than those along separate, aligned scales.

Let's look at salary broken down by the combinations of discipline and
rank. Here, I chose to stratify using color by rank within each of panels
faceting by discipline. Because there is more going on in this plot,
a linear smooth is used to represent the trend. 

```{r}
#| label: fig-Salaries-faceted
#| out-width: "80%"
#| fig-cap: "Scatterplot of Salary vs. years since PhD, grouped by rank, with separate panels for discipline."
Salaries |>
  mutate(discipline = factor(discipline, 
                             labels = c("A: Theoretical", "B: Applied"))) |>
  ggplot(aes(x = yrs.since.phd, y = salary, color = rank)) +
  geom_point() +
  scale_salary +
  labs(x = "Years since PhD",
       y = "Salary") +
  geom_smooth(aes(fill = rank),
              method = "loess", formula = "y ~ x", 
              linewidth = 2) +
  facet_wrap(~ discipline) +
#  theme_bw(base_size = 14) + 
  legend_pos
```
Once both of
these factors are taken into account, there does not seem to be much impact
of years of service.
Salaries in theoretical disciplines are noticeably greater than those in applied
disciplines at all ranks, and there are even greater differences among ranks.


Finally, to shed light on the question that motivated this example---
are there anomalous differences in salary for men and women---
we can look at differences in salary according to sex, when discipline
and rank are taken into account. To do this graphically, condition by both 
variables, but use `facet_grid(discipline ~ rank)` to arrange their combinations
in a grid whose rows are the levels of `discipline` and whose columns are
those of `rank`. I want to make the comparison of males and females most
direct, so I use `color = sex` to stratify the panels. 
The smoothed regression lines and error banks are calculated separately
for each combination of discipline, rank and sex.

```{r}
#| label: fig-Salaries-facet-sex
#| out-width: "100%"
#| fig-cap: "Scatterplot of Salary vs. years since PhD, grouped by sex, faceted by discipline and rank."
Salaries |>
  ggplot(aes(x = yrs.since.phd, y = salary, color = sex)) +
  geom_point() +
  scale_salary +
  labs(x = "Years since PhD",
       y = "Salary") +
  geom_smooth(aes(fill = sex),
              method = "lm", formula = "y ~ x",
              linewidth = 2) +
  facet_grid(discipline ~ rank) +
  theme_bw(base_size = 14) + 
  legend_pos
```

        
```{r child="data-ellipse.qmd"}
```


## Quantitative data: {#sec-quantitative_data}

    + scatterplot matrices
    + parallel coordinate plots

## Categorical data:

    + mosaic plots

## Generalized pair plots


```{r}
#| echo: false
#cat("Packages used here:\n")
write_pkgs(file = .pkg_file)
```

## References {.unnumbered}
