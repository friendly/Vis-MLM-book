```{r include=FALSE}
source(here::here("R", "common.R"))
```

# PCA and Biplots {#sec-pca-biplot}

## _Flatland_ and _Spaceland_ {#sec-spaceland}

There was a cloud in the sky above _Flatland_ one day. But it was a huge, multidimensional cloud of sparkly points that might contain some important message, perhaps like the hidden EUREKA (@fig-pollen-eureka-fig), and perhaps forecasting the upcoming harvest,
if only Flatlanders could appreciate it. 

A leading citizen, A SQUARE, who had traveled once to 
Spaceland and therefore had an inkling of its majesty beyond the simple world of his life in the plane looked at that cloud and had a brilliant thought, an OMG moment:

> "Oh, can I, in my imagination, rotate that cloud and squeeze its' juice so that it rains down on Flatland with greatest joy?"

As it happened, our Square friend, although he could never really _see_ in three dimensions could now 
at least _think_ of a world described by height as well as breadth and width. 

And what a world it was, inhabited by
Pryamids, Cubes and wondrous creatures called Polyhedrons with many corners, sides and faces. Indeed, even exalted Spheres,
having so many faces that its surface became as smooth as a baby's bottom with no need for pointed corners, just as Circles were the smoothest occupants of his world;
he also marveled at Ellipsoids, as smooth as Spheres, but having three natural axes of different extent
and capable of being appearing fatter or slimmer when rotated from different views.

All of these now arose in his richer 3D imagination. 
And all of this came from just one more dimension than life in Flatland.

Up to now, we have also been living in Flatland. We have been trying to understand data in
**data space** of possibly many dimensions, but confined to the 2D plane of a graph window.
Scatterplot matrices and parallel coordinate plots provided some relief ...

## Principal components analysis {#sec-pca}

When Francis Galton [-@Galton:1886] first discovered the idea of regression toward the mean
and presented his famous diagram (@fig-galton-corr), he had little thought that he had provided a
window to a higher-dimensional world, beyond what even A Square could imagine. 
His friend, Karl Pearson [-@Pearson:1896] took that idea and developed it into a theory of
regression and a measure of correlation that would bear his name, Pearson's $r$.

But then Pearson [-@Pearson:1901] had a further inspiration, akin to that of A Square. 
If he also had a cloud of sparkly points in 2, 3, 4, ... dimensions, could he find a
point (0D), or line (1D), or plane (2D), or even a hyperplane ($n$D) that best summarized ---
squeezed out the most juice---from multivariate data?
The best 0D point was easy--- it was simply the centroid, the means of each of the
variables in the data, $(\bar{x}_1, \bar{x}_2, ...)$.



## Biplots {#sec-biplot}

