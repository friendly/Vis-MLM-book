```{r include=FALSE}
source("R/common.R")
clean_pkgs()
```

::: {.content-visible when-format="html"}

::: {.callout-note icon=false appearance="simple"}

Welcome to the online version of *Visualizing Multivariate Data and Models with R*. 

This book will be published by [CRC Press](https://www.routledge.com/corporate/about-us/crc-press). 

:::

:::

# Preface {.unnumbered}

<!-- **TODO**: Make this a more general introduction -->

This book is about graphical methods developed recently for multivariate data, and their uses in understanding relationships when there are several aspects to be considered together. Data visualization methods for statistical analysis are well-developed for simple linear models with a single outcome variable. However, with applied research in the sciences, social and behavioral in particular, it is often the case that the phenomena of interest (e.g., depression, job satisfaction, academic achievement, childhood ADHD disorders, etc.) can be measured in several different ways or related aspects. Understanding how these different aspects are _related_ contributes
to our knowledge of the general phenomenon.

For example, if academic achievement can be measured for adolescents by reading, mathematics, science and history scores, how do predictors such as parental encouragement, school environment and socioeconomic status affect all these outcomes? In a similar way? In different ways? In such cases, much more can be understood from a multivariate approach that considers the correlations among the outcomes. Yet, sadly, researchers typically examine the outcomes one by one which often only tells part of the data story.


However, to do this it is useful to set the stage for multivariate thinking, with a grand scheme for statistics and data visualization, a parable, and an example of multivariate discovery.

<!-- {r child="child/00-one-two-many.qmd"} -->

::: {.callout-warning}
The material in the following subsections are meant to provide motivation for the book and some perspectives that inform it.
These will be moved to a following front-matter chapter, **Preludes**.
:::

## ONE, TWO, MANY

There is an old and helpful idea I learned from John Hartigan in my graduate days at Princeton:

> In statistics and data visualization *all* methods can be classified by the number of dimensions contemplated, on a scale of **ONE**, **TWO**, **MANY**.

By this, he meant that, at a global level, all data, statistical summaries, and graphical displays could be classified as:

-   **univariate**: a single variable, considered in isolation (age, COVID cases, pizzas ordered). Univariate numerical summaries are means, medians, measures of variablilty, and so forth. Univariate displays include dot plots, boxplots, histograms and density estimates.
-   **bivariate**: two variables, considered jointly. Numerical summaries include correlations, covariances and two-way tables of frequencies or measures of association for categorical variables. Bivariate displays include scatterplots and mosaic plots.
-   **multivariate**: three or more variables, considered jointly. Numerical summaries include correlation and covariance matrices, consisting of all pairwise values, but also derived measures from the analysis of these matrices (eigenvalues, eigenvectors). Graphical displays of multivariate data can sometimes be shown in
3D, but often involve multiple views of the data projected into 2D plots.

As a quasi-numerical scale, I refer to these as **1D**, **2D** and **nD**. This admits the possibility of half-integer cases, such as **1.5D**, where the main focus is on a single variable, but that is classified by a simple factor (e.g., gender), or **2.5D** where a 2D scatterplot can show other variables using color, shape or other
visual attributes.
His point in this classification was that once you've reached three variables, all higher dimensions involve similar summaries and data displays.

Univariate and bivariate methods and displays are well-known.  This book is about how these ideas can
be extended to an $n$-dimensional world. Three-dimensional data displays are now fairly easy to produce,
even if they are sometimes difficult to understand. But how can we even think about four or more dimensions?
The difficulty can be appreciated by considering the tale of _Flatland_.


<!-- {r child="child/00-flatland.qmd"} -->


## Flatland

> To comport oneself with perfect propriety in Polygonal society, one ought to be a Polygon oneself.
> --- Edwin A. Abbott, _Flatland_

In 1884, an English schoolmaster, Edwin Abbott Abbott, shook the world of Victorian culture with a 
slim volume, _Flatland: A Romance of Many Dimensions_ [@Abbott:1884]. He described a two-dimensional world, _Flatland_,
inhabited entirely by geometric figures in the plane. His purpose was satirical, to poke fun at the 
social and gender class system at the time:
Women were mere line segments, while men were represented as polygons with varying numbers of sides--- 
a triangle was a working man, but acute isosceles were soldiers or criminals of very small angle; gentlemen and professionals had more sides.
Abbot published this under the pseudonym, "A Square", suggesting his place in the hierarchy.

> True, said the Sphere; it appears to you a Plane, because you are not accustomed to light and shade and
> perspective; just as in Flatland a Hexagon would appear a Straight Line to one who has not the Art of Sight
> Recognition. But in reality it is a Solid, as you shall learn by the sense of Feeling.
> --- Edwin A. Abbott,  _Flatland_


But how did it _feel_ to be a member of a flatland society? How could a point (a newborn child?) understand a
line (a woman)?  How does a Triangle "see" a Hexagon or even a infinitely-sided Circle?
Abbott introduces the very idea of different dimensions of existence through dreams and visions: 

* A Square dreams of visiting a one-dimensional
_Lineland_ where men appear as lines, and women are merely "illustrious points", but the inhabitants
can only see the Square as lines. 

* In a vision, the Square is visited by a Sphere, to illustrate
what a 2D Flatlander could understand from a 3D sphere (@fig-flatland-spheres) that passes through
the plane he inhabits. It is a large circle when seen at the moment of its' greatest extent. As the Spehere rises, it becomes progressively smaller, until it becomes a point, and then vanishes.

```{r}
#| label: fig-flatland-spheres
#| echo: false
#| fig-align: center
#| out-width: "90%"
#| fig-cap: "A 2D Flatlander seeing a sphere as it passes through Flatland. The line, labeled 'My Eye' indicates what the Flatlander would see. Source: @Abbott:1884"
knitr::include_graphics("images/flatland-spheres.jpg")
```

Abbott goes on to state what could be considered as a demonstration (or proof) by induction of the difficulties
of seeing in 1, 2, 3 dimensions, and how the idea motion over time (one more dimension) could 
allow citizens of any 1D, 2D, 3D world to contemplate one more dimension.


> In One Dimensions, did not a moving Point produce a Line with two terminal points? In two Dimensions, did not
> a moving Line produce a Square with four terminal points? In Three Dimensions, did not a moving Square produce
> - did not the eyes of mine behold it - that blessed being, a Cube, with eight terminal points? And in Four
> Dimensions, shall not a moving Cube - alas, for Analogy, and alas for the Progress of Truth if it be not so -
> shall not, I say the motion of a divine Cube result in a still more divine organization with sixteen terminal
> points?
> --- Edwin A. Abbott

For Abbot, the way for a citizen of any world to imagine one more dimension was to consider how a
higher-dimensional object would change over time.[^1-sagan]
A line moved over time could produce a rectangle as shown in @fig-1D-4D; that rectangle moving
in another direction over time would produce a 3D figure, and so forth.

[^1-sagan]: In his famous TV series, _Cosmos_, Carl Sagan provides [an intriguing video presentation](https://youtu.be/UnURElCzGc0) Flatland and the 4th dimension.
However, as far back as 1754 [@Cajori:1926],
the idea of adding a fourth dimension appears in Jean le Rond d'Alembert's "Dimensions",
and one realization of a four-dimensional object is a _tesseract_, shown in @fig-1D-4D.

```{r}
#| label: fig-1D-4D
#| echo: false
#| fig-align: center
#| out-width: "90%"
#| fig-cap: "Geometrical objects in 1 to 4 dimensions. One more dimension can be thought of as the trace of movement over time."
knitr::include_graphics("images/1D-4D.png")
```

But wait! Where does that 4D thing (a _tesseract_) come from?
To really see a tesseract it helps to view it in an animation over time (@fig-tesseract).
But like the Square, contemplating 3D from a
2D world, it takes some imagination.

<!-- ::: {.content-visible when-format="html"} -->

<!-- :::: {#fig-tesseract} -->

<!-- ```{=html} -->
<!-- <div align="center"> -->
<!-- <iframe width="256" height="256" src="images/tesseract.gif"></iframe> -->
<!-- </div> -->
<!-- ``` -->

<!-- Animation of a tesseract, a cube changing over time. -->
<!-- :::: -->

<!-- ::: -->

::: {.content-visible when-format="html"}

![Animation of a tesseract, a cube changing over time.](images/tesseract.gif){#fig-tesseract}

:::


::: {.content-visible when-format="PDF"}

![Frames from an animation of a tesseract, a cube changing over time. This appears as a true animation in the online version.](images/tesseract-frames.png){#fig-tesseract}
:::

Yet the deep mathematics of more than three dimensions only emerged in the 19th century.
In Newtonian mechanics, space and time were always considered independent of each other. 
Our familiar three-dimensional space, of length, width, and height had formed the backbone of Euclidean geometry for millenea.

However, the idea that space and time are indeed interwoven was first proposed by German mathematician Hermann Minkowski (1864--1909) in a 1908 lecture titled "Space and Time".[^minkowski] 
This was a powerful idea. It bore fruit when
Albert Einstein revolutionized the Newtonian conceptions of gravity in 1915 when he presented a theory of general relativity which was based primarily on the fact that mass and energy warp the fabric of four-dimensional spacetime.

[^minkowski]: See the translation by Lewertoff and Petkov, "Space and Time
Minkowski’s Papers on Relativity", https://bit.ly/45NvgZR

The parable of _Flatland_ can provide inspiration for statistical thinking and data visualization.
Once we go beyond bivariate statistics and 2D plots, we are in a multivariate world of
possibly MANY dimensions. It takes only some imagination and suitable methods to get there.

Like Abbott's _Flatland_, this book is a romance, in many dimensions, of what we can learn from modern methods
of data visualization.


<!-- {r child="child/00-eureka.qmd"} -->

## EUREKA!

Even modest sized multivariate data can have secrets that can be revealed in the right view.
As an example, David Coleman at RCA Laboratories in Princeton, N.J. generated a dataset of
five (fictitious) measurements of grains of pollen for the 1986 Data Exposition at the
Joint statistical Meetings.
The first three variables are the lengths of geometric features 3848 observed sampled pollen grains -- in the x, y, and z dimensions: a `ridge` along x, a `nub` in the y
direction, and a `crack` in along the z dimension.  The fourth
variable is pollen grain `weight`, and the fifth is `density`.
The challenge was to "find something interesting" in this dataset, now available as `r dataset("pollen")`.
<!-- \ixd{pollen} -->
\ixp{animation}

Those who solved the puzzle were able to find an orientation of this 5-dimensional dataset, such that
zooming in revealed a magic word, "EUREKA" spelled in points, as in the following figure.

::: {#fig-pollen-eureka layout-nrow=2}
![](images/pollen-eureka1.png){width=40%}

![](images/pollen-eureka2.png){width=40%}

![](images/pollen-eureka4.png){width=40%}

![](images/pollen-eureka3.png){width=40%}

Four views of the `pollen` data, zooming in, clockwise from the upper left to discover the word "EUREKA".

:::

::: {.content-visible when-format="html"}

This can be seen better in a 3D animation. The `rgl` package [@R-rgl] is used to create a 3D scatterplot of the first three
variables. Then the `animation` package [@R-animation] is use to record a sequence of images, adjusting the
`rgl::par3d(zoom)` value.

```{r}
#| label: pollen-eureka-code
#| code-fold: true
#| code-summary: "Show the code"
#| eval: false
#| fig-cap: "Animation of the `pollen` data, zooming in to reveal the word \"EUREKA\". " 
library(animation)
library(rgl)
data(pollen, package = "animation")
oopt = ani.options(interval = 0.05)
## adjust the viewpoint
uM =
  matrix(c(-0.3709192276, -0.5133571028, -0.7738776206, 0, 
           -0.7305060625,  0.6758151054, -0.0981751680, 0, 
            0.57339602708, 0.5289064049, -0.6256819367, 0, 
           0, 0, 0, 1), 4, 4)
open3d(userMatrix = uM, 
       windowRect = c(10, 10, 510, 510))

plot3d(pollen[, 1:3])

# zoom in
zm = seq(1, 0.045, length = 200)
par3d(zoom = 1)
for (i in 1:length(zm)) {
  par3d(zoom = zm[i])
  ani.pause()
}
ani.options(oopt)
```


:::: {#fig-pollen-eureka}
![Animation of zooming in on the `pollen` data to reveal the word "EUREKA". This figure only appears in the online version.](images/pollen-eureka.gif)
::::

:::

::: {.content-visible when-format="pdf"}
The path to finding the hidden word can be seen better in a 3D animation. The online version of the book uses
The `rgl` package [@R-rgl] create a 3D scatterplot of the first three
variables. Then the `animation` package [@R-animation] is use to record a sequence of images, adjusting the
`rgl::par3d(zoom)` value.
\ixp{rgl}
\ixp{animation}
:::

## Multivariate scientific discoveries {#sec-discoveries}

Lest this example seem contrived (which it admittedly is), multivariate visualization has played an important role in quite a few scientific discoveries. Among these, Francis Galton's [-@Galton:1863] discovery of the
anti-cyclonic pattern of wind direction in relation to barometric pressure from many weather measures
recorded systematically across all weather stations, lighthouses and observatories in Europe in December 1861
stands out as the best example of a scientific discovery achieved almost entirely through graphical means–-- something that was totally unexpected, and purely the product of his use of remarkably novel high-dimensional graphs [@FriendlyWainer:2021:TOGS, p. 170-173].

A more recent example is the discovery of two general classes in the development of Type 2 diabetes by
@ReavenMiller:79, using PRIM-9 [@Fishkeller-etal:1974b], the first computer system for high-dimensional
visualization[^prim9]. In an earlier study @ReavenMiller:68 examined the relation between blood glucose
levels and the production of insulin in normal subjects and in patients with varying degrees of
hyperglicemia (elevated blood sugar level).
They found a peculiar ''horse shoe'' shape in this relation (shown in @fig-diabetes1), about which they could only speculate: perhaps individuals with the best glucose tolerance also had the lowest levels of insulin as a response to an oral dose of glucose; perhaps those with low glucose response could secrete higher levels of insulin; perhaps those who were low on both glucose and insulin responses followed some other mechanism.
In 2D plots, this was a mystery.

[^prim9]: PRIM-9 is an acronym for **P**icturing, **R**otation, **I**solation and **M**asking in up to **9** dimensions. These operations are fundamental to interactive and dynamic data visualization.


```{r echo=-1}
#| label: fig-diabetes1
#| out-width: "70%"
#| code-fold: false
#| fig-cap: "Reproduction of a graph similar to that from @ReavenMiller:68 on the relationship between glucose and insulin response to being given an oral dose of glucose."
op <- par(mar = c(5, 5, 1, 1) + .1)
data(Diabetes, package="heplots")
plot(instest ~ glutest, data=Diabetes, 
     pch=16,
     cex.lab=1.25,
     xlab="Glucose response",
     ylab="Insulin response")
```

<!-- knitr::include_graphics("images/diabetes1.png") -->

An answer to their questions came ten years later, when they were able to
visualize similar but new data in 3D using the PRIM-9 system. In a carefully
controlled study, they also measured ''steady state plasma glucose'' (SSPG), a
measure of the efficiency of use of insulin in the body, where large values mean
insulin resistance, as well as other variables. PRIM-9 allowed them to explore
various sets of three variables, and, more importantly, to rotate a given plot
in three dimensions to search for interesting features. One plot that stood out
concerned the relation between plasma glucose response, plasma insulin response
and SSPG response, shown in @fig-ReavenMiller-3d.

```{r}
#| label: fig-ReavenMiller-3d
#| echo: false
#| out-width: "70%"
#| fig-cap: "Artist's rendition of data from @ReavenMiller:79 as seen in three dimensions using the PRIM-9 system. Labels for the clusters have been added, identifying the three groups of patients. _Source_: @ReavenMiller:79."
knitr::include_graphics("images/ReavenMiller-3d-annotated.png")
```

From this graphical insight, they were able to classify the participants
into three groups, based on clinical levels of glucose and insulin. The
people in the wing on the left in @fig-ReavenMiller-3d were considered to have overt diabetes, the most advanced form,
characterized by elevated fasting blood glucose concentration and classical diabetic symptoms.
Those in the right wing were classified as latent or
chemical diabetics, with no symptoms of diabetes but demonstrable abnormality of oral or intravenous glucose tolerance.
Those in the central blob were classified as normal.

Previous thinking was that Type 2 diabetes (when the body cannot make _enough_ insulin, as opposed to Type I,
an autoimmune condition where the pancreatic cells have been destroyed) progressed from
the chemical stage to an overt one in a smooth transition. However, it was clear from @fig-ReavenMiller-3d
that the only "path" from one to the other lead through the cluster of normal patients near the origin,
so that explanation must be wrong. Instead, this suggested that the chemical and overt diabetics were
distinct classes. Indeed, longitudinal studies showed that patients classified as chemical diabetics
rarely developed the overt form. The understanding of the etiology of Type 2 diabetes was
altered dramatically by the power of high-D interactive graphics.

## Features

Some key substantive and pedagogical features of the book are:

* Statistical data visualization is cast in a general framework by their **goal** for communicating information, either to your self or others (such as see the _data_, visualize a _model_, diagnose _problems_), rather than a categorization by **graphic types**. It is best informed by principles and goals
of communication, for example making graphic comparison easy and ordering factors and variables according to what should be seen (_effect ordering_).

*	Data visualization is seen as a combination of **exposure**---plotting the raw data---and **summarization**--- plotting statistical summaries---to highlight what should be noticed. For example, data ellipses and confidence ellipses are widely used as simple, effective summaries of data and fitted model parameters. When the data is complex, the idea of **visual thinning** can be used to balance the tradeoff.

* The book exploits the rich connections among **statistics**, **geometry** and **data visualization**. Statistical ideas, particularly for multivariate data, can be more easily understood in terms of geometrical ones that can be seen in diagrams and data displays. Moreover, ideas from one domain
can amplify what we can understand from another.

*	These graphical tools can be used to understand or explain a wide variety of statistical concepts, phenomena, and paradoxes such as Simpson's paradox, effects of measurement error, and so forth.

*	The HE ("hypothesis - error") plot framework provides a simple way to understand the results of statistical tests and the relations among response outcomes in the multivariate linear model.

*	Dimension reduction techniques such as PCA and discriminant analysis are presented as "multivariate juicers," able to squeeze the important information in high-dimensional data into informative two-dimensional views.


## What I assume

It is assumed that the reader has at least a basic background in _applied, intermediate_ statistics. This would normally
include material on simple regression and multiple regression as well as simple analysis of variance (ANOVA) designs.
It also means that you should be familiar with 
the basic ideas of statistical inference including hypothesis tests and confidence intervals.
**TODO**: Complete this required background

There will also be some mathematics in the book where words and diagrams are not enough.
The mathematical level will be intermediate, mostly consisting of simple algebra. No derivations, proofs, theorems here!

For multivariate methods, it will be useful to express ideas using **matrix notation** to simplify presentation. 
It will be enough for you to recognize that a single symbol $\mathbf{y}$ can be a shorthand for $n$ scores on a
variable like weight, and
the symbol $\mathbf{X}$ can represent an entire data table, with, say $n$ observations on $p$ variables
like height, body mass index, diet components, and so forth.
Then, the notation $\mathbf{y} = \mathbf{X} \boldsymbol{\beta}$
represents an entire linear model to relate weight to these other variables.
I'm using this math notation to express ideas, and all you will need is a reading-level of understanding.

For this, the first chapter of @Fox2021, _A Mathematical Primer for Social Statistics_, is excellent,
and the rest is well worth reading.
If you want to learn something of using matrix algebra for data analysis and statistics, I recommend
our package `r pkg("matlib", cite=TRUE)`.

## R Resources

I also assume the reader to have at least a basic familiarity with statistical analysis in R.
While R fundamentals are outside the scope of the book, I believe that this language provides a rich set of resources, far beyond that offered by other statistical software packages, and is well worth learning.
For those not familiar with R or wish to learn new skills, I recommend:

* Cotton [-@Cotton-2013], _Learning R_  ([online](http://duhi23.github.io/Analisis-de-datos/Cotton.pdf));
* Matloff[-@Matloff-2011], _The Art of R Programming_  ([online](https://diytranscriptomics.com/Reading/files/The%20Art%20of%20R%20Programming.pdf));
* Wickham[-@Wickham2019], _Advanced R_  ([online](https://adv-r.hadley.nz/)) is aimed at intermediate R programmers who want to dive deeper into R and learn how things work,
* Long & Teetor [-@LongTeetor2019], _R Cookbook_ 2$^{nd}$ Ed ([online](https://rc2e.com/)) provides how-to recipies for
basic tasks from working with RStudio, to input and output, general statistics, graphics, and regression / ANOVA;
* Fox & Weisberg [-@FoxWeisberg:2018], _An R Companion to Applied Regression_  is a fantastic resource for learning
how to perform statistical analyses in R and visualize results with insightful graphics. It is the companion book
to Fox's [-@Fox:2016:ARA], _Applied Regression Analysis and Generalized Linear Models_, which I consider the 
best intermediate-level
modern treatment of these topics. I make heavy use of the accompanying `r package("car", cite=TRUE)` which provides
important and convenient graphical methods.


## R graphics resources

In this book, I create a large number of graphs in R, and have aimed to present and _describe_ how I do them using
R packages and code to manipulate the data or numerical output from analysis function, so that you can learn from these
examples to apply these ideas to your own data. 

In writing this, I've also tried to exemplify graphical principles that underlie effective graphic communication.
You might find the lecture notes, extensive resources and R examples for my course, 
[_Psychology of Data Visualization_](https://friendly.github.io/6135/) useful.

In addition, there are a few books I recommend:

* Claus Wilke [-@Wilke2019], _Fundamentals of Data Visualization_ ([online](https://clauswilke.com/dataviz/))
Well thought out, a wide range of topics, good practical advice, lots of examples.
Online version: https://clauswilke.com/dataviz/
Course notes: https://wilkelab.org/SDS375/

* Nicola Rennie [-@Rennie2025], _The Art of Data Visualization with ggplot2_ ([online](https://nrennie.rbind.io/art-of-viz/))


**TODO**: Add more stuff on general books about graphics




## Conventions used in this book

<!-- **TODO**: Some stuff below is just for testing... Revise. -->

The following typographic conventions are used in this book:

* _italic_ : indicates terms or phrases to be _emphasized_ or defined in the text; **bold** : is used for terms
to be given **strong emphasis**, particularly for their first mention.

* Package names are printed in **bold** and colored `r colorize("brown", "brown4")`, for example
  `r pkg("ggplot2")`, `r pkg("car")` and the `r package("matlib")`. These uses generate citations like
  `r pkg("ggplot2", cite = TRUE)`. Package references in the text are automatically indexed,
  individually and under a "Packages" heading.

* Datasets are rendered as their name in monospaced font, like `r dataset("Prestige", "carData")` or 
indicating the package from which they come, as in `r dataset("carData::Prestige")`. These too are automatically
indexed.

* A monospaced `typewriter` font is used in the text to refer to _variable_ and _function_ names, 
such as `education` and `plot()`. This font is also for R statement elements, keywords and code framents as well.

* R code in program listings and output is presented in a `monospaced (typewriter)` font,
  [`fira mono`](https://fonts.google.com/specimen/Fira+Mono)

<!-- * _`fixed-width italic`_ : isn't used yet, but probably should be. -->

* For R functions in packages, I use the notation `package::function()`, for example: `car::Anova()`, to identify 
that the `Anova()` function is defined in the `r pkg("car")` package. This also means you can get help on
a function by typing `?car::Anova` in the console, or a list of its arguments and default values from
`args(car::Anova)`. 

## Acknowledgements

Acknowledgements will go here.

<!-- ## References {.unnumbered} -->

\mainmatter
