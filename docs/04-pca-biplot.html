<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Visualizing Multivariate Data and Models in R - 4&nbsp; PCA and Biplots</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./linear_models.html" rel="next">
<link href="./03-multivariate_plots.html" rel="prev">
<link href="./images/favicon/favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04-pca-biplot.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">PCA and Biplots</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Visualizing Multivariate Data and Models in R</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/friendly/vis-MLM-book" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-getting_started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Getting Started</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-multivariate_plots.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Plots of Multivariate Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-pca-biplot.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">PCA and Biplots</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Overview of Linear models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_models-plots.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Plots for univariate response models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./collinearity-ridge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Collinearity &amp; Ridge Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hotelling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hotelling’s <span class="math inline">\(T^2\)</span></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlm-viz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Visualizing Multivariate Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlm-review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Brief review of the multivariate linear model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./case-studies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Case studies</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eqcov.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Visualizing Tests for Equality of Covariance Matrices</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./90-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-spaceland" id="toc-sec-spaceland" class="nav-link active" data-scroll-target="#sec-spaceland"><span class="header-section-number">4.1</span> <em>Flatland</em> and <em>Spaceland</em></a>
  <ul class="collapse">
<li><a href="#multivariate-juicers" id="toc-multivariate-juicers" class="nav-link" data-scroll-target="#multivariate-juicers"><span class="header-section-number">4.1.1</span> Multivariate juicers</a></li>
  </ul>
</li>
  <li>
<a href="#sec-pca" id="toc-sec-pca" class="nav-link" data-scroll-target="#sec-pca"><span class="header-section-number">4.2</span> Principal components analysis</a>
  <ul class="collapse">
<li><a href="#pca-by-springs" id="toc-pca-by-springs" class="nav-link" data-scroll-target="#pca-by-springs"><span class="header-section-number">4.2.1</span> PCA by springs</a></li>
  <li><a href="#mathematics-and-geometry-of-pca" id="toc-mathematics-and-geometry-of-pca" class="nav-link" data-scroll-target="#mathematics-and-geometry-of-pca"><span class="header-section-number">4.2.2</span> Mathematics and geometry of PCA</a></li>
  <li><a href="#finding-principal-components" id="toc-finding-principal-components" class="nav-link" data-scroll-target="#finding-principal-components"><span class="header-section-number">4.2.3</span> Finding principal components</a></li>
  <li><a href="#visualizing-variance-proportions-screeplots" id="toc-visualizing-variance-proportions-screeplots" class="nav-link" data-scroll-target="#visualizing-variance-proportions-screeplots"><span class="header-section-number">4.2.4</span> Visualizing variance proportions: screeplots</a></li>
  <li><a href="#visualizing-pca-scores-and-variable-vectors" id="toc-visualizing-pca-scores-and-variable-vectors" class="nav-link" data-scroll-target="#visualizing-pca-scores-and-variable-vectors"><span class="header-section-number">4.2.5</span> Visualizing PCA scores and variable vectors</a></li>
  </ul>
</li>
  <li>
<a href="#sec-biplot" id="toc-sec-biplot" class="nav-link" data-scroll-target="#sec-biplot"><span class="header-section-number">4.3</span> Biplots</a>
  <ul class="collapse">
<li><a href="#constructing-a-biplot" id="toc-constructing-a-biplot" class="nav-link" data-scroll-target="#constructing-a-biplot"><span class="header-section-number">4.3.1</span> Constructing a biplot</a></li>
  <li><a href="#biplots-in-r" id="toc-biplots-in-r" class="nav-link" data-scroll-target="#biplots-in-r"><span class="header-section-number">4.3.2</span> Biplots in R</a></li>
  <li><a href="#example" id="toc-example" class="nav-link" data-scroll-target="#example"><span class="header-section-number">4.3.3</span> Example</a></li>
  <li><a href="#biplot-contributions-and-quality" id="toc-biplot-contributions-and-quality" class="nav-link" data-scroll-target="#biplot-contributions-and-quality"><span class="header-section-number">4.3.4</span> Biplot contributions and quality</a></li>
  <li><a href="#sec-supp-vars" id="toc-sec-supp-vars" class="nav-link" data-scroll-target="#sec-supp-vars"><span class="header-section-number">4.3.5</span> Supplementary variables</a></li>
  </ul>
</li>
  <li><a href="#sec-var-order" id="toc-sec-var-order" class="nav-link" data-scroll-target="#sec-var-order"><span class="header-section-number">4.4</span> Application: Variable ordering for data displays</a></li>
  <li><a href="#application-eigenfaces" id="toc-application-eigenfaces" class="nav-link" data-scroll-target="#application-eigenfaces"><span class="header-section-number">4.5</span> Application: Eigenfaces</a></li>
  <li><a href="#elliptical-insights-outlier-detection" id="toc-elliptical-insights-outlier-detection" class="nav-link" data-scroll-target="#elliptical-insights-outlier-detection"><span class="header-section-number">4.6</span> Elliptical insights: Outlier detection</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/friendly/vis-MLM-book/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-pca-biplot" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">PCA and Biplots</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><section id="sec-spaceland" class="level2" data-number="4.1"><h2 data-number="4.1" class="anchored" data-anchor-id="sec-spaceland">
<span class="header-section-number">4.1</span> <em>Flatland</em> and <em>Spaceland</em>
</h2>
<blockquote class="blockquote">
<p>It is high time that I should pass from these brief and discursive notes about Flatland to the central event of this book, my initiation into the mysteries of Space. THAT is my subject; all that has gone before is merely preface — Edwin Abbott, <em>Flatland</em>, p.&nbsp;57.</p>
</blockquote>
<p>There was a cloud in the sky above <em>Flatland</em> one day. But it was a huge, multidimensional cloud of sparkly points that might contain some important message, perhaps like the hidden EUREKA (<a href="index.html#fig-pollen-eureka-fig">Figure&nbsp;<span>5</span></a>), or perhaps forecasting the upcoming harvest, if only Flatlanders could appreciate it.</p>
<p>A leading citizen, A SQUARE, who had traveled once to Spaceland and therefore had an inkling of its majesty beyond the simple world of his life in the plane looked at that cloud and had a brilliant thought, an OMG moment:</p>
<blockquote class="blockquote">
<p>“Oh, can I, in my imagination, rotate that cloud and squeeze its’ juice so that it rains down on Flatland with greatest joy?”</p>
</blockquote>
<p>As it happened, our Square friend, although he could never really <em>see</em> in three dimensions, he could now at least <em>think</em> of a world described by <strong>height</strong> as well as breadth and width, and think of the <strong>shadow</strong> cast by a cloud as something mutable, changing size and shape depending on its’ orientation over Flatland.</p>
<p>And what a world it was, inhabited by Pryamids, Cubes and wondrous creatures called Polyhedrons with many <span class="math inline">\(C\)</span>orners, <span class="math inline">\(F\)</span>aces and <span class="math inline">\(E\)</span>dges. Not only that, but all those Polyhedra were forced in Spaceland to obey a magic formula: <span class="math inline">\(C + F - E = 2\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> How cool was that!</p>
<p>Indeed, there were even exalted Spheres, having so many faces that its surface became as smooth as a baby’s bottom with no need for pointed corners or edges, just as Circles were the smoothest occupants of his world with far too many sides to count. It was his dream of a Sphere passing through Flatland (<a href="index.html#fig-flatland-spheres">Figure&nbsp;<span>1</span></a>) that first awakened him to a third dimension.</p>
<p>He also marveled at Ellipsoids, as smooth as Spheres, but in Spaceland having three natural axes of different extent and capable of being appearing fatter or slimmer when rotated from different views. An Ellipsoid had magical properties: it could appear as so thin in one or more dimensions that it became a simple 2D ellipse, or a 1D line, or even a 0D point <span class="citation" data-cites="Friendly-etal:ellipses:2013">(<a href="90-references.html#ref-Friendly-etal:ellipses:2013" role="doc-biblioref">Friendly et al., 2013</a>)</span>. <!-- **TODO**: somehow mention the `gellipsoid` package here. --></p>
<p>All of these now arose in Square’s richer 3D imagination. And, all of this came from just one more dimension than his life in Flatland.</p>
<section id="multivariate-juicers" class="level3" data-number="4.1.1"><h3 data-number="4.1.1" class="anchored" data-anchor-id="multivariate-juicers">
<span class="header-section-number">4.1.1</span> Multivariate juicers</h3>
<p>Up to now, we have also been living in Flatland. We have been trying to understand data in <strong>data space</strong> of possibly many dimensions, but confined to the 2D plane of a graph window. Scatterplot matrices and parallel coordinate plots provided some relief. The former did so by <strong>projecting</strong> the data into sets of 2D views in the coordinates of data space; the latter did so by providing multiple axes in a 2D space along which we could trace the paths of individual observations.</p>
<p>This chapter is about seeing data in a different projection, a low-dimensional, usually 2D, space that which squeezes out the most juice from multidimensional data for a particular purpose (<a href="#fig-MV-juicer">Figure&nbsp;<span>4.1</span></a>), where what we want to understand can be more easily seen.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-MV-juicer" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/MV-juicer.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.1: A multivariate juicer takes data from possibly high-dimensional data space and transforms it to a lower-dimenional space in which important effects can be more easily seen.</figcaption></figure>
</div>
</div>
</div>
<p>Here, I concentrate on <strong>principal components analysis</strong> (PCA), whose goal reflects A Square’s desire to see that sparkly cloud of points in <span class="math inline">\(nD\)</span> space in the plane showing the greatest variation (squeezing the most juice) among all other possible views. This appealed to his sense of geometry, but left him wondering how the variables in that high-D cloud were related to the dimensions he could see in a best-fitting plane.</p>
<p>The idea of a <strong>biplot</strong>, showing the data points in the plane, together with thick pointed arrows—variable vectors— in one view is the other topic explained in this chapter (<a href="#sec-biplot"><span>Section&nbsp;4.3</span></a>). The biplot is the simplest example of a multivariate juicer. The essential idea is to project the cloud of data points in <span class="math inline">\(n\)</span> dimensions into the 2D space of principal components and simultaneously show how the original variables relate to this space. For exploratory analysis to get an initial, incisive view of a multivariate dataset, a biplot is often my first choice.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Looking ahead">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Looking ahead
</div>
</div>
<div class="callout-body-container callout-body">
<p>I’m using the term <em>multivariate juicer</em> here to refer the wider class of <strong>dimension reduction</strong> techniques, used for various purposes in data analysis and visualization. Principal components analysis is the simplest example and illustrates the general ideas.</p>
<p>The key point is that these methods are designed to transform the data into a low-dimensional space for a particular goal or purpose. In PCA, the goal is to extract the greatest amount of total variability in the data. In the context of univariate multiple regression, the goal is often to reduce the number of predictors necessary to account for an outcome variable, called <em>feature extraction</em> in the machine learning literature.</p>
<p>When the goal is to best distinguish among groups <strong>discriminant analysis</strong> finds uncorrelated weighted sums of predictors on which the means of groups are most widely separated in a reduced space of hopefully fewer dimensions.</p>
<p>The methods I cover in this book are all linear methods, but there is also a wide variety of non-linear dimension reduction techniques …</p>
</div>
</div>
<p><strong>Packages</strong></p>
<p>In this chapter I use the following packages. Load them now:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org">tidyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/friendly/ggbiplot">ggbiplot</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://factominer.free.fr">FactoMineR</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sthda.com/english/rpkgs/factoextra">factoextra</a></span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section><section id="sec-pca" class="level2" data-number="4.2"><h2 data-number="4.2" class="anchored" data-anchor-id="sec-pca">
<span class="header-section-number">4.2</span> Principal components analysis</h2>
<p>When Francis Galton <span class="citation" data-cites="Galton:1886">(<a href="90-references.html#ref-Galton:1886" role="doc-biblioref">1886</a>)</span> first discovered the idea of regression toward the mean and presented his famous diagram (<a href="03-multivariate_plots.html#fig-galton-corr">Figure&nbsp;<span>3.9</span></a>), he had little thought that he had provided a window to a higher-dimensional world, beyond what even A Square could imagine. His friend, Karl Pearson <span class="citation" data-cites="Pearson:1896">(<a href="90-references.html#ref-Pearson:1896" role="doc-biblioref">1896</a>)</span> took that idea and developed it into a theory of regression and a measure of correlation that would bear his name, Pearson’s <span class="math inline">\(r\)</span>.</p>
<p>But then Pearson <span class="citation" data-cites="Pearson:1901">(<a href="90-references.html#ref-Pearson:1901" role="doc-biblioref">1901</a>)</span> had a further inspiration, akin to that of A Square. If he also had a cloud of sparkly points in <span class="math inline">\(2, 3, 4, ..., p\)</span> dimensions, could he find a point (<span class="math inline">\(0D\)</span>), or line (<span class="math inline">\(1D\)</span>), or plane (<span class="math inline">\(2D\)</span>), or even a hyperplane (<span class="math inline">\(nD\)</span>) that best summarized — squeezed out the most juice—from multivariate data? This was the first trully multivariate problem in the history of statistics <span class="citation" data-cites="FriendlyWainer:2021:TOGS">(<a href="90-references.html#ref-FriendlyWainer:2021:TOGS" role="doc-biblioref">Friendly &amp; Wainer, 2021, p. 186</a>)</span>.</p>
<p>The best <span class="math inline">\(0D\)</span> point was easy— it was simply the centroid, the means of each of the variables in the data, <span class="math inline">\((\bar{x}_1, \bar{x}_2, ..., \bar{x}_p)\)</span>, because that was “closest” to the data in the sense of minimizing the sum of squared differences, <span class="math inline">\(\Sigma_i\Sigma_j (x_{ij} - \bar{x}_j)^2\)</span>. In higher dimensions, his solution was also an application of the method of least squares, but he argued it geometrically and visually as shown in <a href="#fig-Pearson1901">Figure&nbsp;<span>4.2</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-Pearson1901" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/Pearson1901.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.2: Karl Pearson’s (1901) geometric, visual argument for finding the line or plane of closest fit to a collection of points, P1, P2, P3, …</figcaption></figure>
</div>
</div>
</div>
<p>For a <span class="math inline">\(1D\)</span> summary, the line of best fit to the points <span class="math inline">\(P_1, P_2, \dots P_n\)</span> is the line that goes through the centroid and made the average squared length of the <em>perpendicular</em> segments from those points to a line as small as possible. This was different from the case in linear regression, for fitting <span class="math inline">\(y\)</span> from <span class="math inline">\(x\)</span>, where the average squared length of the <em>vertical</em> segments, <span class="math inline">\(\Sigma_i (y_i - \hat{y}_i)^2\)</span> was minimized by least squares.</p>
<p>He went on to prove the visual insights from simple smoothing of <span class="citation" data-cites="Galton:1886">Galton (<a href="90-references.html#ref-Galton:1886" role="doc-biblioref">1886</a>)</span> (shown in <a href="03-multivariate_plots.html#fig-galton-corr">Figure&nbsp;<span>3.9</span></a>) regarding the regression lines of <code>y ~ x</code> and <code>x ~ y</code>. More importantly, he proved that the cloud of points is captured, for the purpose of finding a best line, plane or hyperplane, by the ellipsoid that encloses it, as seen in his diagram, <a href="#fig-Pearson1901-2">Figure&nbsp;<span>4.3</span></a>. The major axis of the 2D ellipse is the line of best fit, along which the data points have the smallest average squared distance from the line. The axis at right angles to that—the minor axis— is labeled “line of worst fit” with the largest average squared distance.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-Pearson1901-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/Pearson1901_2.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.3: Karl Pearson’s diagram showing the elliptical geometry of regression and principal components analysis … <em>Source</em>: Pearson (1901), p.&nbsp;566.</figcaption></figure>
</div>
</div>
</div>
<p>Even more importantly— and this is the basis for what we call <strong>principal components analysis</strong> (PCA)— he recognized that the two orthogonal axes of the ellipse gave new coordinates for the data which were uncorrelated, whatever the correlation of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
<blockquote class="blockquote">
<p>Physically, the axes of the correlation type-ellipse are the directions of independent and uncorrelated variation. — <span class="citation" data-cites="Pearson:1901">Pearson (<a href="90-references.html#ref-Pearson:1901" role="doc-biblioref">1901</a>)</span>, p.&nbsp;566.</p>
</blockquote>
<p>It was but a small step to recognize that for two variables, <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>:</p>
<ul>
<li>the line of best fit, the major axis (PC1) had the greatest variance of points projected onto it;</li>
<li>the line of worst fit, the minor axis (PC2), had the least variance;</li>
<li>these could be seen as a rotation of the data space of <span class="math inline">\((x, y)\)</span> to a new space (PC1, PC2) with uncorrelated variables;</li>
<li>the total variation of the points in data space, <span class="math inline">\(\text{Var}(x) + \text{Var}(y)\)</span>, being unchanged by rotation, was equally well expressed as the total variation <span class="math inline">\(\text{Var}(PC1) + \text{Var}(PC2)\)</span> of the scores on what are now called the principal component axes.</li>
</ul>
<p>It would have appealed to Pearson (and also to A Square) to see these observations demonstrated in a 3D video. <a href="#fig-pca-animation">Figure&nbsp;<span>4.4</span></a> shows a 3D plot of the variables <code>Sepal.Length</code>, <code>Sepal.Width</code> and <code>Petal.Length</code> in Edgar Anderson’s <code>iris</code> data, with points colored by species and the 95% data ellipsoid. This is rotated smoothly by interpolation until the first two principal axes, PC1 and PC2 are aligned with the horizontal and vertical dimensions. Because this is a rigid rotation of the cloud of points, the total variability is obviously unchanged.</p>
<!-- ::: {#fig-pca-animation} -->
<!-- <div align="center"> -->
<!-- <iframe width="946" height="594" src="images/pca-animation1.gif"></iframe> -->
<!-- </div> -->
<!-- Animation of PCA as a rotation in 3D space. The plot shows three variables for the `iris` data, initially -->
<!-- in data space and its' data ellipsoid, with points colored according to species of the iris flowers. This is rotated smoothly until the first two principal axes are aligned with the horizontal and vertical dimensions. -->
<!-- ::: -->
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-pca-animation" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/pca-animation1.gif" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.4: Animation of PCA as a rotation in 3D space. The plot shows three variables for the #| <code>iris</code> data, initially in data space and its’ data ellipsoid, with points colored according #| to species of the iris flowers. This is rotated smoothly until the first two principal axes #| are aligned with the horizontal and vertical dimensions.</figcaption></figure>
</div>
</div>
</div>
<section id="pca-by-springs" class="level3" data-number="4.2.1"><h3 data-number="4.2.1" class="anchored" data-anchor-id="pca-by-springs">
<span class="header-section-number">4.2.1</span> PCA by springs</h3>
<p>Before delving into the mathematics of PCA, it is useful to see how Pearson’s problem, and fitting by least squares generally, could be solved in a physical realization.</p>
<p>From elementary statistics, you may be familiar with a physical demonstration that the mean, <span class="math inline">\(\bar{x}\)</span>, of a sample is the value for which the sum of deviations, <span class="math inline">\(\Sigma_i (x_i - \bar{x})\)</span> is zero, so the mean can be visualized as the point of balance on a line where those differences <span class="math inline">\((x_i - \bar{x})\)</span> are placed. Equally well, there is a physical realization of the mean as the point along an axis where weights connected by springs will minimize the sum of squared differences, because springs with a constant stiffness, <span class="math inline">\(k\)</span>, exert forces proportional to <span class="math inline">\(k (x_i - \bar{x}) ^2\)</span>. That’s the reason is useful as a measure of central tendency: it minimizes the average squared error.</p>
<p>In two dimensions, imagine that we have points, <span class="math inline">\((x_i, y_i)\)</span> and these are attached by springs of equal stiffness <span class="math inline">\(k\)</span>, to a line anchored at the centroid, <span class="math inline">\((\bar{x}, \bar{y})\)</span> as shown in <a href="#fig-pca-springs">Figure&nbsp;<span>4.5</span></a>. If we rotate the line to some initial position and release it, the springs will pull the line clockwise or counterclockwise and the line will bounce around until the forces, proportional to the squares of the lengths of the springs, will eventually balance out at the position (shown by the <span style="color: red;">red</span> fixed line segments at the ends). This is the position that minimizes the the sum of squared lengths of the connecting springs, and also minimizes the kinetic energy in the system.</p>
<p>If you look closely at <a href="#fig-pca-springs">Figure&nbsp;<span>4.5</span></a> you will see something else: When the line is at its’ final position of minimum squared length and energy, the positions of the <span style="color: red;">red</span> points on this line are spread out furthest, i.e., have <strong>maximum</strong> variance. Conversely, when the line line is at right angles to its’ final position (shown by the black line at 90<span class="math inline">\(^o\)</span>) the projected points have the smallest possible variance.</p>
<div id="fig-pca-springs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><div data-align="center">
<iframe width="412" height="364" src="images/pca-springs-cropped.gif">
</iframe>
</div>
<figcaption class="figure-caption">Figure&nbsp;4.5: Animation of PCA fitted by springs. The <span style="color: blue;">blue</span> data points are connected to their projections on the <span style="color: red;">red</span> line by springs perpendicular to that line. From an initial position, the springs pull that line in proportion to their squared distances, until the line finally settles down to the position where the forces are balanced and the minimum is achieved. <em>Source</em>: Amoeba, https://bit.ly/46tAicu.</figcaption></figure>
</div>
<!-- See: https://joshualoftus.com/posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html -->
<p><strong>TODO</strong>: Simple PCA example using workers data</p>
</section><section id="mathematics-and-geometry-of-pca" class="level3" data-number="4.2.2"><h3 data-number="4.2.2" class="anchored" data-anchor-id="mathematics-and-geometry-of-pca">
<span class="header-section-number">4.2.2</span> Mathematics and geometry of PCA</h3>
<p>As the ideas of principal components developed, there was a happy marriage of Galton’s geometrical intuition and Pearson’s mathematical analysis. The best men at the wedding were ellipses and higher-dimensional ellipsoids. The brides maids were eigenvectors, pointing in as many different directions as space would allow, each sized according to their associated eigenvalues. Attending the wedding were the ghosts of uncles, Leonhard Euler, Jean-Louis Lagrange, Augustin-Louis Cauchy and others who had earlier discovered the mathematical properties of ellipses and quadratic forms in relation to problems in physics.</p>
<p>The key idea in the statistical application was that, for a set of variables <span class="math inline">\(\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_p\)</span>, the <span class="math inline">\(p \times p\)</span> covariance matrix <span class="math inline">\(\mathbf{S}\)</span> could be expressed <strong>exactly</strong> as a matrix product involving a matrix <span class="math inline">\(\mathbf{V}\)</span>, whose columns are <em>eigenvectors</em> (<span class="math inline">\(\mathbf{v}_i\)</span>) and a diagonal matrix <span class="math inline">\(\mathbf{\Lambda}\)</span>, whose diagonal elements (<span class="math inline">\(\lambda_i\)</span>) are the corresponding <em>eigenvalues</em>.</p>
<p>To explain this, it is helpful to use a bit of matrix math:</p>
<p><span class="math display">\[\begin{align*}
\mathbf{S}_{p \times p} &amp; = \mathbf{V}_{p \times p} \quad\quad \mathbf{\Lambda}_{p \times p} \quad\quad \mathbf{V}_{p \times p}^T \\
           &amp; = \left( \mathbf{v}_1, \, \mathbf{v}_2, \,\dots, \, \mathbf{v}_p \right)
           \begin{pmatrix}
             \lambda_1 &amp;  &amp;  &amp; \\
             &amp; \lambda_2  &amp;   &amp; \\
             &amp;  &amp; \ddots &amp; \\
             &amp;  &amp;  &amp; \lambda_p
            \end{pmatrix}
            
            \begin{pmatrix}
            \mathbf{v}_1^T\\
            \mathbf{v}_2^T\\
            \vdots\\
            \mathbf{v}_p^T\\
            \end{pmatrix}
           \\
           &amp; = \lambda_1 \mathbf{v}_1 \mathbf{v}_1^T + \lambda_2 \mathbf{v}_2 \mathbf{v}_2^T + \cdots + \lambda_p \mathbf{v}_p \mathbf{v}_p^T
\end{align*}\]</span></p>
<p>In this equation,</p>
<ul>
<li><p>The last line follows because <span class="math inline">\(\mathbf{\Lambda}\)</span> is a diagonal matrix, so <span class="math inline">\(\mathbf{S}\)</span> is expressed as a sum of outer products of each <span class="math inline">\(\mathbf{v}_i\)</span> with itself.<br></p></li>
<li><p>The columns of <span class="math inline">\(\mathbf{V}\)</span> are the eigenvectors of <span class="math inline">\(\mathbf{S}\)</span>. They are orthogonal and of unit length, so <span class="math inline">\(\mathbf{V}^T \mathbf{V} = \mathbf{I}\)</span> and thus they represent orthogonal (uncorrelated) directions in data space.</p></li>
<li><p>The columns <span class="math inline">\(\mathbf{v}_i\)</span> are the weights applied to the variables to produce the scores on the principal components. For example, the first principal component is the weighted sum:</p></li>
</ul>
<p><span class="math display">\[
PC1 = v_{11} \mathbf{x}_1 + v_{12} \mathbf{x}_2 + \cdots + v_{1p} \mathbf{x}_p
\]</span></p>
<ul>
<li><p>The eigenvalues, <span class="math inline">\(\lambda_1, \lambda_2, \dots, \lambda_p\)</span> are the variances of the the components, because <span class="math inline">\(\mathbf{v}_i^T \;\mathbf{S} \; \mathbf{v}_i = \lambda_i\)</span>.</p></li>
<li><p>It is usually the case that the variables <span class="math inline">\(\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_p\)</span> are linearly independent, which means that none of these is an exact linear combination of the others. In this case, all eigenvalues <span class="math inline">\(\lambda_i\)</span> are positive and the covariance matrix <span class="math inline">\(\mathbf{S}\)</span> is said to have <strong>rank</strong> <span class="math inline">\(p\)</span>.</p></li>
<li><p>Here is the key fact: If the eigenvalues are arranged in order, so that <span class="math inline">\(\lambda_1 &gt; \lambda_2 &gt; \dots &gt; \lambda_p\)</span>, then the first <span class="math inline">\(d\)</span> components give a <span class="math inline">\(d\)</span>-dimensional approximation to <span class="math inline">\(\mathbf{S}\)</span>, which accounts for <span class="math inline">\(\Sigma_i^d \lambda_i / \Sigma_i^p \lambda_i\)</span> of the total variance.</p></li>
</ul>
<p>For the case of two variables, <span class="math inline">\(\mathbf{x}_1\)</span> and <span class="math inline">\(\mathbf{x}_2\)</span> <a href="#fig-pca-rotation">Figure&nbsp;<span>4.6</span></a> shows the transformation from data space to component space. The eigenvectors, <span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2\)</span> are the major and minor axes of the data ellipse, whose lengths are the square roots <span class="math inline">\(\sqrt{\lambda_1}, \sqrt{\lambda_2}\)</span> of the eigenvalues.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-pca-rotation" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/pca-rotation.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.6: Geometry of PCA as a rotation from data space to principal component space, defined by the eigenvectors v1 and v2 of a covariance matrix</figcaption></figure>
</div>
</div>
</div>
</section><section id="finding-principal-components" class="level3" data-number="4.2.3"><h3 data-number="4.2.3" class="anchored" data-anchor-id="finding-principal-components">
<span class="header-section-number">4.2.3</span> Finding principal components</h3>
<p>In R, principal components analysis is most easily carried out using <code><a href="https://rdrr.io/r/stats/prcomp.html">stats::prcomp()</a></code> or <code><a href="https://rdrr.io/r/stats/princomp.html">stats::princomp()</a></code> or similar functions in other packages such as <code>FactomineR::PCA()</code>. The <strong>FactoMineR</strong> package <span class="citation" data-cites="R-FactoMineR Husson-etal-2017">(<a href="90-references.html#ref-Husson-etal-2017" role="doc-biblioref">Husson et al., 2017</a>, <a href="90-references.html#ref-R-FactoMineR" role="doc-biblioref">2023</a>)</span> has extensive capabilities for exploratory analysis of multivariate data (PCA, correspondence analysis, cluster analysis).</p>
<p>A particular strength of FactoMineR for PCA is that it allows the inclusion of <em>supplementary variables</em> (which can be categorical or quantitative) and <em>supplementary points</em> for individuals. These are not used in the analysis, but are projected into the plots to facilitate interpretation. For example, in the analysis of the <code>crime</code> data described below, it would be useful to have measures of other characteristics of the U.S. states, such as poverty and average level of education (<a href="#sec-supp-vars"><span>Section&nbsp;4.3.5</span></a>).</p>
<p>Unfortunately, although all of these functions perform similar calculations, the options for analysis and the details of the result they return differ.</p>
<p>The important options for analysis include:</p>
<ul>
<li>whether or not the data variables are <strong>centered</strong>, to a mean of <span class="math inline">\(\bar{x}_j =0\)</span>
</li>
<li>whether or not the data variables are <strong>scaled</strong>, to a variance of <span class="math inline">\(\text{Var}(x_j) =1\)</span>.</li>
</ul>
<p>It nearly always makes sense to center the variables. The choice of scaling determines whether the correlation matrix is analyzed, so that each variable contributes equally to the total variance that is to be accounted for versus analysis of the covariance matrix, where each variable contributes its own variance to the total. Analysis of the covariance matrix makes little sense when the variables are measured on different scales.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<section id="example-crime-data" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="example-crime-data">Example: Crime data</h4>
<p>The dataset <code>crime</code>, analysed in <a href="03-multivariate_plots.html#sec-corrgram"><span>Section&nbsp;3.2.2</span></a>, showed all positive correlations among the rates of various crimes in the corrgram, <a href="03-multivariate_plots.html#fig-crime-corrplot">Figure&nbsp;<span>3.27</span></a>. What can we see from a principal components analysis? Is it possible that a few dimensions can account for most of the juice in this data?</p>
<p>In this example, you can easily find the PCA solution using <code><a href="https://rdrr.io/r/stats/prcomp.html">prcomp()</a></code> in a single line in base-R. You need to specify the numeric variables to analyze by their columns in the data frame. The most important option here is <code>scale. = TRUE</code> …</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">crime</span>, package <span class="op">=</span> <span class="st">"ggbiplot"</span><span class="op">)</span></span>
<span><span class="va">crime.pca</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/prcomp.html">prcomp</a></span><span class="op">(</span><span class="va">crime</span><span class="op">[</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">8</span><span class="op">]</span>, scale. <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The tidy equivalent is more verbose, but also more expressive about what is being done. It selects the variables to analyze by a function, <code><a href="https://rdrr.io/r/base/numeric.html">is.numeric()</a></code> applied to each of the columns and feeds the result to <code><a href="https://rdrr.io/r/stats/prcomp.html">prcomp()</a></code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">crime.pca</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">crime</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/where.html">where</a></span><span class="op">(</span><span class="va">is.numeric</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/prcomp.html">prcomp</a></span><span class="op">(</span>scale. <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As is typical with models in R, the result, <code>crime.pca</code> of <code><a href="https://rdrr.io/r/stats/prcomp.html">prcomp()</a></code> is an object of class <code>"prcomp"</code>, a list of components, and there are a variety of methods for <code>"prcomp"</code> objects. Among the simplest is <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code>, which gives the contributions of each component to the total variance in the dataset.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">crime.pca</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span>digits<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; Importance of components:</span></span>
<span><span class="co">#&gt;                         PC1  PC2  PC3   PC4   PC5   PC6   PC7</span></span>
<span><span class="co">#&gt; Standard deviation     2.03 1.11 0.85 0.563 0.508 0.471 0.352</span></span>
<span><span class="co">#&gt; Proportion of Variance 0.59 0.18 0.10 0.045 0.037 0.032 0.018</span></span>
<span><span class="co">#&gt; Cumulative Proportion  0.59 0.76 0.87 0.914 0.951 0.982 1.000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The object, <code>crime.pca</code> returned by <code><a href="https://rdrr.io/r/stats/prcomp.html">prcomp()</a></code> is a list of the following the following elements:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">crime.pca</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "sdev"     "rotation" "center"   "scale"    "x"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Of these, for <span class="math inline">\(n\)</span> observations and <span class="math inline">\(p\)</span> variables,</p>
<ul>
<li>
<code>sdev</code> is the length <span class="math inline">\(p\)</span> vector of the standard deviations of the principal components (i.e., the square roots <span class="math inline">\(\sqrt{\lambda_i}\)</span> of the eigenvalues of the covariance/correlation matrix). When the variables are standardized, the sum of squares of the eigenvalues is equal to <span class="math inline">\(p\)</span>.</li>
<li>
<code>rotation</code> is the <span class="math inline">\(p \times p\)</span> matrix of weights or <strong>loadings</strong> of the variables on the components; the columns are the eigenvectors of the covariance or correlation matrix of the data;</li>
<li>
<code>x</code> is the <span class="math inline">\(n \times p\)</span> matrix of <strong>scores</strong> for the observations on the components, the result of multiplying (rotating) the data matrix by the loadings. These are uncorrelated, so <code>cov(x)</code> is a <span class="math inline">\(p \times p\)</span> diagonal matrix whose diagonal elements are the eigenvalues <span class="math inline">\(\lambda_i\)</span> = <code>sdev^2</code>.</li>
</ul></section></section><section id="visualizing-variance-proportions-screeplots" class="level3" data-number="4.2.4"><h3 data-number="4.2.4" class="anchored" data-anchor-id="visualizing-variance-proportions-screeplots">
<span class="header-section-number">4.2.4</span> Visualizing variance proportions: screeplots</h3>
<p>For a high-D dataset, such as the crime data in seven dimensions, a natural question is how much of the variation in the data can be captured in 1D, 2D, 3D, … summaries and views. This is answered by considering the proportions of variance accounted by each of the dimensions, or their cumulative values. The components returned by various PCA methods have (confusingly) different names, so <code><a href="https://generics.r-lib.org/reference/tidy.html">broom::tidy()</a></code> provides methods to unify extraction of these values.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="va">crime.eig</span> <span class="op">&lt;-</span> <span class="va">crime.pca</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">broom</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span>matrix <span class="op">=</span> <span class="st">"eigenvalues"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 7 × 4</span></span>
<span><span class="co">#&gt;      PC std.dev percent cumulative</span></span>
<span><span class="co">#&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1     1   2.03   0.588       0.588</span></span>
<span><span class="co">#&gt; 2     2   1.11   0.177       0.765</span></span>
<span><span class="co">#&gt; 3     3   0.852  0.104       0.868</span></span>
<span><span class="co">#&gt; 4     4   0.563  0.0452      0.914</span></span>
<span><span class="co">#&gt; 5     5   0.508  0.0368      0.951</span></span>
<span><span class="co">#&gt; 6     6   0.471  0.0317      0.982</span></span>
<span><span class="co">#&gt; 7     7   0.352  0.0177      1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, a simple visualization is a plot of the proportion of variance for each component (or cumulative proportion) against the component number, usually called a <strong>screeplot</strong>. The idea, introduced by <span class="citation" data-cites="Cattell1966">Cattell (<a href="90-references.html#ref-Cattell1966" role="doc-biblioref">1966</a>)</span>, is that after the largest, dominant components, the remainder should resemble the rubble, or scree formed by rocks falling from a cliff.</p>
<p>From this plot, imagine drawing a straight line through the plotted eigenvalues, starting with the largest one. The typical rough guidance is that the last point to fall on this line represents the last component to extract, the idea being that beyond this, the amount of additional variance explained is non-meaningful. Another rule of thumb is to choose the number of components to extract a desired proportion of total variance, usually in the range of 80 - 90%.</p>
<p><code>stats::plot(crime.pca)</code> would give a bar plot of the variances of the components, however <code><a href="https://rdrr.io/pkg/ggbiplot/man/ggscreeplot.html">ggbiplot::ggscreeplot()</a></code> gives nicer and more flexible displays as shown in <a href="#fig-crime-ggscreeplot">Figure&nbsp;<span>4.7</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/ggscreeplot.html">ggscreeplot</a></span><span class="op">(</span><span class="va">crime.pca</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">stat_smooth</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">crime.eig</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">PC</span><span class="op">&gt;=</span><span class="fl">4</span><span class="op">)</span>, </span>
<span>              <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">PC</span>, y<span class="op">=</span><span class="va">percent</span><span class="op">)</span>, method <span class="op">=</span> <span class="st">"lm"</span>, </span>
<span>              se <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>              fullrange <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/ggscreeplot.html">ggscreeplot</a></span><span class="op">(</span><span class="va">crime.pca</span>, type <span class="op">=</span> <span class="st">"cev"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.8</span>, <span class="fl">0.9</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p1</span> <span class="op">+</span> <span class="va">p2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-crime-ggscreeplot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-crime-ggscreeplot-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.7: Screeplots for the PCA of the crime data. The left panel shows the traditional version, plotting variance proportions against component number, with linear guideline for the scree rule of thumb. The right panel plots cumulative proportions, showing cutoffs of 80%, 90%.</figcaption></figure>
</div>
</div>
</div>
<p>From this we might conclude that four components are necessary to satisfy the scree criterion or to account for 90% of the total variation in these crime statistics. However two components, giving 76.5%, might be enough juice to tell a reasonable story.</p>
</section><section id="visualizing-pca-scores-and-variable-vectors" class="level3" data-number="4.2.5"><h3 data-number="4.2.5" class="anchored" data-anchor-id="visualizing-pca-scores-and-variable-vectors">
<span class="header-section-number">4.2.5</span> Visualizing PCA scores and variable vectors</h3>
<p>To see and attempt to understand PCA results, it is useful to plot both the scores for the observations on a few of the largest components and also the loadings or variable vectors that give the weights for the variables in determining the principal components.</p>
<p>In <a href="#sec-biplot"><span>Section&nbsp;4.3</span></a> I discuss the biplot technique that plots both in a single display. However, I do this directly here, using tidy processing to explain what is going on in PCA and in these graphical displays.</p>
<section id="scores" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="scores">Scores</h4>
<p>The (uncorrelated) principal component scores can be extracted as <code>crime.pca$x</code> or using <code>purrr::pluck("x")</code>. As noted above, these are uncorrelated and have variances equal to the eigenvalues of the correlation matrix.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">scores</span> <span class="op">&lt;-</span> <span class="va">crime.pca</span> <span class="op">|&gt;</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/pluck.html">pluck</a></span><span class="op">(</span><span class="st">"x"</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">scores</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/zapsmall.html">zapsmall</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;      PC1  PC2  PC3  PC4  PC5  PC6  PC7</span></span>
<span><span class="co">#&gt; PC1 4.11 0.00 0.00 0.00 0.00 0.00 0.00</span></span>
<span><span class="co">#&gt; PC2 0.00 1.24 0.00 0.00 0.00 0.00 0.00</span></span>
<span><span class="co">#&gt; PC3 0.00 0.00 0.73 0.00 0.00 0.00 0.00</span></span>
<span><span class="co">#&gt; PC4 0.00 0.00 0.00 0.32 0.00 0.00 0.00</span></span>
<span><span class="co">#&gt; PC5 0.00 0.00 0.00 0.00 0.26 0.00 0.00</span></span>
<span><span class="co">#&gt; PC6 0.00 0.00 0.00 0.00 0.00 0.22 0.00</span></span>
<span><span class="co">#&gt; PC7 0.00 0.00 0.00 0.00 0.00 0.00 0.12</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For plotting, it is more convenient to use <code><a href="https://generics.r-lib.org/reference/augment.html">broom::augment()</a></code> which extracts the scores (named <code>.fittedPC*</code>) and appends these to the variables in the dataset.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">crime.pca</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">broom</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">crime</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 6 × 18</span></span>
<span><span class="co">#&gt;   .rownames state      murder  rape robbery assault burglary larceny</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 1         Alabama      14.2  25.2    96.8    278.    1136.   1882.</span></span>
<span><span class="co">#&gt; 2 2         Alaska       10.8  51.6    96.8    284     1332.   3370.</span></span>
<span><span class="co">#&gt; 3 3         Arizona       9.5  34.2   138.     312.    2346.   4467.</span></span>
<span><span class="co">#&gt; 4 4         Arkansas      8.8  27.6    83.2    203.     973.   1862.</span></span>
<span><span class="co">#&gt; 5 5         California   11.5  49.4   287      358     2139.   3500.</span></span>
<span><span class="co">#&gt; 6 6         Colorado      6.3  42     171.     293.    1935.   3903.</span></span>
<span><span class="co">#&gt; # ℹ 10 more variables: auto &lt;dbl&gt;, st &lt;chr&gt;, region &lt;fct&gt;,</span></span>
<span><span class="co">#&gt; #   .fittedPC1 &lt;dbl&gt;, .fittedPC2 &lt;dbl&gt;, .fittedPC3 &lt;dbl&gt;,</span></span>
<span><span class="co">#&gt; #   .fittedPC4 &lt;dbl&gt;, .fittedPC5 &lt;dbl&gt;, .fittedPC6 &lt;dbl&gt;,</span></span>
<span><span class="co">#&gt; #   .fittedPC7 &lt;dbl&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, we can use <code><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot()</a></code> to plot any pair of components. To aid interpretation, I label the points by their state abbreviation and color them by <code>region</code> of the U.S.. A geometric interpretation of the plot requires an aspect ratio of 1.0 (via <code><a href="https://ggplot2.tidyverse.org/reference/coord_fixed.html">coord_fixed()</a></code>) so that a unit distance on the horizontal axis is the same length as a unit distance on the vertical. To demonstrate that the components are uncorrelated, I also added their data ellipse.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">crime.pca</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">broom</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">crime</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># add original dataset back in</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">.fittedPC1</span>, <span class="va">.fittedPC2</span>, color <span class="op">=</span> <span class="va">region</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>label <span class="op">=</span> <span class="va">st</span><span class="op">)</span>, nudge_x <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/stat_ellipse.html">stat_ellipse</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_fixed.html">coord_fixed</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"PC Dimension 1"</span>, y <span class="op">=</span> <span class="st">"PC Dimnension 2"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-crime-scores-plot12" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-crime-scores-plot12-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.8: Plot of component scores on the first two principal components for the <code>crime</code> data. States are colored by <code>region</code>.</figcaption></figure>
</div>
</div>
</div>
<p>To interpret such plots, it is useful consider the observations that are a high and low on each of the axes as well as other information, such as region here, and ask how these differ on the crime statistics. The first component, PC1, contrasts Nevada and California with North Dakota, South Dakota and West Virginia. The second component has most of the southern states on the low end and Massachusetts, Rhode Island and Hawaii on the high end. However, interpretation is easier when we also consider how the various crimes contribute to these dimensions.</p>
<p>When, as here, there are more than two components that seem important in the scree plot, we could obviously go further and plot other pairs.</p>
</section><section id="variable-vectors" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="variable-vectors">Variable vectors</h4>
<p>You can extract the variable loadings using either <code>crime.pca$rotation</code> or <code>purrr::pluck("rotation")</code>, similar to what I did with the scores.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">crime.pca</span> <span class="op">|&gt;</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/pluck.html">pluck</a></span><span class="op">(</span><span class="st">"rotation"</span><span class="op">)</span></span>
<span><span class="co">#&gt;             PC1     PC2     PC3     PC4     PC5     PC6     PC7</span></span>
<span><span class="co">#&gt; murder   -0.300 -0.6292  0.1782 -0.2321  0.5381  0.2591  0.2676</span></span>
<span><span class="co">#&gt; rape     -0.432 -0.1694 -0.2442  0.0622  0.1885 -0.7733 -0.2965</span></span>
<span><span class="co">#&gt; robbery  -0.397  0.0422  0.4959 -0.5580 -0.5200 -0.1144 -0.0039</span></span>
<span><span class="co">#&gt; assault  -0.397 -0.3435 -0.0695  0.6298 -0.5067  0.1724  0.1917</span></span>
<span><span class="co">#&gt; burglary -0.440  0.2033 -0.2099 -0.0576  0.1010  0.5360 -0.6481</span></span>
<span><span class="co">#&gt; larceny  -0.357  0.4023 -0.5392 -0.2349  0.0301  0.0394  0.6017</span></span>
<span><span class="co">#&gt; auto     -0.295  0.5024  0.5684  0.4192  0.3698 -0.0573  0.1470</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>But note something important in this output: All of the weights for the first component are negative. In PCA, the directions of the eigenvectors are completely arbitrary, in the sense that the vector <span class="math inline">\(-\mathbf{v}_i\)</span> gives the same linear combination as <span class="math inline">\(\mathbf{v}_i\)</span>, but with its’ sign reversed. For interpretation, it is useful (and usually recommended) to reflect the loadings to a positive orientation by multiplying them by -1.</p>
<p>To reflect the PCA loadings and get them into a convenient format for plotting with <code><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot()</a></code>, it is necessary to do a bit of processing, including making the <code><a href="https://rdrr.io/r/base/row.names.html">row.names()</a></code> into an explicit variable for the purpose of labeling.</p>
<p><strong>TODO</strong>: Should this be a callout-warning or a footnote??</p>
<div class="callout callout-style-default callout-warning callout-titled" title="`rownames` in R">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<code>rownames</code> in R
</div>
</div>
<div class="callout-body-container callout-body">
<p>R software evolved over many years, particularly in conventions for labeling cases in printed output and graphics. In base-R, the convention was that the <code><a href="https://rdrr.io/r/base/row.names.html">row.names()</a></code> of a matrix or data.frame served as observation labels in all printed output and plots, with a default to use numbers <code>1:n</code> if there were no rownames. In <code>ggplot2</code> and the <code>tidyverse</code> framework, the decision was made that observation labels had to be an <strong>explicit</strong> variable in a “tidy” dataset, so it could be used as a variable in constructs like <code>geom_text(aes(label = label))</code> as in this example. This change often requires extra steps in software that uses the rownames convention.</p>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vectors</span> <span class="op">&lt;-</span> <span class="va">crime.pca</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/pluck.html">pluck</a></span><span class="op">(</span><span class="st">"rotation"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>PC1 <span class="op">=</span> <span class="op">-</span><span class="fl">1</span> <span class="op">*</span> <span class="va">PC1</span>, PC2 <span class="op">=</span> <span class="op">-</span><span class="fl">1</span> <span class="op">*</span> <span class="va">PC2</span><span class="op">)</span> <span class="op">|&gt;</span>      <span class="co"># reflect axes</span></span>
<span>  <span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/rownames.html">rownames_to_column</a></span><span class="op">(</span>var <span class="op">=</span> <span class="st">"label"</span><span class="op">)</span> </span>
<span></span>
<span><span class="va">vectors</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span>
<span><span class="co">#&gt;      label   PC1     PC2</span></span>
<span><span class="co">#&gt; 1   murder 0.300  0.6292</span></span>
<span><span class="co">#&gt; 2     rape 0.432  0.1694</span></span>
<span><span class="co">#&gt; 3  robbery 0.397 -0.0422</span></span>
<span><span class="co">#&gt; 4  assault 0.397  0.3435</span></span>
<span><span class="co">#&gt; 5 burglary 0.440 -0.2033</span></span>
<span><span class="co">#&gt; 6  larceny 0.357 -0.4023</span></span>
<span><span class="co">#&gt; 7     auto 0.295 -0.5024</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, I plot these using <code><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment()</a></code>, taking some care to use arrows from the origin with a nice shape and add <code><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text()</a></code> labels for the variables positioned slightly to the right. Again, <code><a href="https://ggplot2.tidyverse.org/reference/coord_fixed.html">coord_fixed()</a></code> ensures equal scales for the axes, which is important because we want to interpret the angles between the variable vectors and the PCA coordinate axes.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">arrow_style</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/grid/arrow.html">arrow</a></span><span class="op">(</span></span>
<span>  angle <span class="op">=</span> <span class="fl">20</span>, ends <span class="op">=</span> <span class="st">"first"</span>, type <span class="op">=</span> <span class="st">"closed"</span>, </span>
<span>  length <span class="op">=</span> <span class="fu">grid</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/grid/unit.html">unit</a></span><span class="op">(</span><span class="fl">8</span>, <span class="st">"pt"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">vectors</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">PC1</span>, <span class="va">PC2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span>xend <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fl">0</span>, </span>
<span>               linewidth <span class="op">=</span> <span class="fl">1</span>, </span>
<span>               arrow <span class="op">=</span> <span class="va">arrow_style</span>,</span>
<span>               color <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>label <span class="op">=</span> <span class="va">label</span><span class="op">)</span>, </span>
<span>            size <span class="op">=</span> <span class="fl">5</span>,</span>
<span>            hjust <span class="op">=</span> <span class="st">"outward"</span>,</span>
<span>            nudge_x <span class="op">=</span> <span class="fl">0.05</span>, </span>
<span>            color <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">xlim</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.4</span>, <span class="fl">0.9</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.8</span>, <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_fixed.html">coord_fixed</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-crime-vectors" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-crime-vectors-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.9: Plot of component loadings the first two principal components for the <code>crime</code> data. These are interpreted as the contributions of the variables to the components.</figcaption></figure>
</div>
</div>
</div>
<p>What is shown in <a href="#fig-crime-vectors">Figure&nbsp;<span>4.9</span></a> has the following interpretations:</p>
<ol type="1">
<li><p>the lengths of the variable vectors, <span class="math inline">\(||\mathbf{v}_i|| = \sqrt{\Sigma_{j = 1}^{j=2} \; v_{ij}^2}\)</span> give the proportion of variance of each variable accounted for in a two-dimensional display.</p></li>
<li><p>the value, <span class="math inline">\(v_{ij}\)</span>, of the vector for variable <span class="math inline">\(\mathbf{x}_i\)</span> on component <span class="math inline">\(j\)</span> gives the correlation of that variable with the <span class="math inline">\(j\)</span>th principal component.</p></li>
<li><p>the cosine of the angle between two variable vectors, <span class="math inline">\(\mathbf{v}_i\)</span> and <span class="math inline">\(\mathbf{v}_j\)</span> gives the approximation of the correlation between <span class="math inline">\(\mathbf{x}_i\)</span> and <span class="math inline">\(\mathbf{x}_j\)</span> that is shown in this space. This means that two variable vectors that point in the same direction are highly correlated, while variable vectors at right angles are approximately uncorrelated.</p></li>
</ol>
<p>To illustrate point (1), the following indicates that almost 70% of the variance of <code>murder</code> is represented in the the 2D plot shown in <a href="#fig-crime-scores-plot12">Figure&nbsp;<span>4.8</span></a>, but only 40% of the variance of <code>robbery</code> is captured.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vectors</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">label</span>, <span class="va">PC1</span>, <span class="va">PC2</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>length <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">PC1</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">PC2</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      label   PC1     PC2 length</span></span>
<span><span class="co">#&gt; 1   murder 0.300  0.6292  0.697</span></span>
<span><span class="co">#&gt; 2     rape 0.432  0.1694  0.464</span></span>
<span><span class="co">#&gt; 3  robbery 0.397 -0.0422  0.399</span></span>
<span><span class="co">#&gt; 4  assault 0.397  0.3435  0.525</span></span>
<span><span class="co">#&gt; 5 burglary 0.440 -0.2033  0.485</span></span>
<span><span class="co">#&gt; 6  larceny 0.357 -0.4023  0.538</span></span>
<span><span class="co">#&gt; 7     auto 0.295 -0.5024  0.583</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section></section><section id="sec-biplot" class="level2" data-number="4.3"><h2 data-number="4.3" class="anchored" data-anchor-id="sec-biplot">
<span class="header-section-number">4.3</span> Biplots</h2>
<p>The biplot is a simple and powerful idea that came from the recognition that you can overlay a plot of observation scores in a principal components analysis with the information of the variable loadings (weights) to give a simultaneous display that is easy to interpret. In this sense, a biplot is generalization of a scatterplot, projecting from data space to PCA space, where the observations are shown by points, as in the plots of component scores in <a href="#fig-crime-scores-plot12">Figure&nbsp;<span>4.8</span></a>, but with the variables also shown by vectors (or scaled linear axes aligned with those vectors).</p>
<p>The idea of the biplot was introduced by Ruben Gabriel <span class="citation" data-cites="Gabriel:71 Gabriel:81">(<a href="90-references.html#ref-Gabriel:71" role="doc-biblioref">1971</a>, <a href="90-references.html#ref-Gabriel:81" role="doc-biblioref">1981</a>)</span> and later expanded in scope by <span class="citation" data-cites="GowerHand:96">Gower &amp; Hand (<a href="90-references.html#ref-GowerHand:96" role="doc-biblioref">1996</a>)</span>. The book by <span class="citation" data-cites="Greenacre:2010:biplots">Greenacre (<a href="90-references.html#ref-Greenacre:2010:biplots" role="doc-biblioref">2010</a>)</span> gives a practical overview of the many variety of biplots and <span class="citation" data-cites="Gower-etal:2011">Gower et al. (<a href="90-references.html#ref-Gower-etal:2011" role="doc-biblioref">2011</a>)</span> provide a full treatment …</p>
<p>Biplot methodolgy is far more general than I cover here. Categorical variables can be incorporated in PCA using category level points. Two-way frequency tables of categorical variables can be analysed using <em>correspondence analysis</em>, which is similar to PCA, but designed to account for the maximum amount of the <span class="math inline">\(\chi^2\)</span> statistic for association; <em>multiple correspondence analysis</em> extends this to method to multi-way tables <span class="citation" data-cites="FriendlyMeyer:2016:DDAR Greenacre:84">(<a href="90-references.html#ref-FriendlyMeyer:2016:DDAR" role="doc-biblioref">Friendly &amp; Meyer, 2016</a>; <a href="90-references.html#ref-Greenacre:84" role="doc-biblioref">Greenacre, 1984</a>)</span>.</p>
<section id="constructing-a-biplot" class="level3" data-number="4.3.1"><h3 data-number="4.3.1" class="anchored" data-anchor-id="constructing-a-biplot">
<span class="header-section-number">4.3.1</span> Constructing a biplot</h3>
<p>The biplot is constructed by using the singular value decomposition (SVD) to obtain a low-rank approximation to the data matrix <span class="math inline">\(\mathbf{X}_{n \times p}\)</span> (centered, and optionally scaled to unit variances) whose <span class="math inline">\(n\)</span> rows are the observations and whose <span class="math inline">\(p\)</span> columns are the variables.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-svd-diagram" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/SVD-eqn.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.10: The singular value decomposition expresses a data matrix <strong>X</strong> as the product of a matrix <strong>U</strong> of observation scores, a diagonal matrix <strong>Lambda</strong> of singular values and a matrix <strong>V</strong> of variable weights. <strong>TODO</strong>: Re-draw to fix notation.</figcaption></figure>
</div>
</div>
</div>
<p>Using the SVD, the matrix <span class="math inline">\(\mathbf{X}\)</span>, of rank <span class="math inline">\(r \le p\)</span> can be expressed <em>exactly</em> as: <span id="eq-svd1"><span class="math display">\[
\mathbf{X} = \mathbf{U} \mathbf{\Lambda} \mathbf{V}'
                 = \sum_i^r \lambda_i \mathbf{u}_i \mathbf{v}_i' \; ,
\tag{4.1}\]</span></span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\mathbf{U}\)</span> is an <span class="math inline">\(n \times r\)</span> orthonormal matrix of uncorrelated observation scores; these are also the eigenvectors of <span class="math inline">\(\mathbf{X} \mathbf{X}'\)</span>,</li>
<li>
<span class="math inline">\(\mathbf{\Lambda}\)</span> is an <span class="math inline">\(r \times r\)</span> diagonal matrix of singular values, <span class="math inline">\(\lambda_1 \ge \lambda_2 \ge \cdots \lambda_r\)</span>, which are also the square roots of the eigenvalues of <span class="math inline">\(\mathbf{X} \mathbf{X}'\)</span>.</li>
<li>
<span class="math inline">\(\mathbf{V}\)</span> is an <span class="math inline">\(r \times p\)</span> orthonormal matrix of observation scores and also the eigenvectors of <span class="math inline">\(\mathbf{X}' \mathbf{X}\)</span>.</li>
</ul>
<p>Then, a rank 2 (or 3) PCA approximation <span class="math inline">\(\widehat{\mathbf{X}}\)</span> to the data matrix used in the biplot can be obtained from the first 2 (or 3) singular values <span class="math inline">\(\lambda_i\)</span> and the corresponding <span class="math inline">\(\mathbf{u}_i, \mathbf{v}_i\)</span> as:</p>
<p><span class="math display">\[
\mathbf{X} \approx \widehat{\mathbf{X}} = \lambda_1 \mathbf{u}_1 \mathbf{v}_1' + \lambda_2 \mathbf{u}_2 \mathbf{v}_2' \; .
\]</span></p>
<p>The variance of <span class="math inline">\(\mathbf{X}\)</span> accounted for by each term is <span class="math inline">\(\lambda_i^2\)</span>.</p>
<p>A biplot is then obtained by overlaying two scatterplots that share a common set of axes and have a between-set scalar product interpretation. Typically, the observations (rows of <span class="math inline">\(\mathbf{X}\)</span>) are represented as points and the variables (columns of <span class="math inline">\(\mathbf{X}\)</span>) are represented as vectors from the origin.</p>
<p>The factor, <span class="math inline">\(\alpha\)</span> allows the variances of the components to be apportioned between the row points and column vectors, with different interpretations, by representing the approximation <span class="math inline">\(\widehat{\mathbf{X}}\)</span> as the product of two matrices,</p>
<p><span class="math display">\[
\widehat{\mathbf{X}} = (\mathbf{U} \mathbf{\Lambda}^\alpha) (\mathbf{\Lambda}^{1-\alpha} \mathbf{V}') = \mathbf{A} \mathbf{B}'
\]</span> This notation uses a little math trick involving a power, <span class="math inline">\(0 \le \alpha \le 1\)</span>: When <span class="math inline">\(\alpha = 1\)</span>, <span class="math inline">\(\mathbf{\Lambda}^\alpha = \mathbf{\Lambda}^1 =\mathbf{\Lambda}\)</span>, and <span class="math inline">\(\mathbf{\Lambda}^{1-\alpha} = \mathbf{\Lambda}^0 =\mathbf{I}\)</span>. <span class="math inline">\(\alpha = 1/2\)</span> gives the diagonal matrix <span class="math inline">\(\mathbf{\Lambda}^{1/2}\)</span> whose elements are the square roots of the singular values.</p>
<p>The choice <span class="math inline">\(\alpha = 1\)</span> assigns the singular values totally to the left factor; then, the angle between two variable vectors, reflecting the inner product <span class="math inline">\(\mathbf{x}_j^T, \mathbf{x}_{j'}\)</span> approximates their correlation or covariance, and the distance between the points approximates their Mahalanobis distances. <span class="math inline">\(\alpha = 0\)</span> gives a distance interpretation to the column display. <span class="math inline">\(\alpha = 1/2\)</span> gives a symmetrically scaled biplot. *TODO**: Explain this better.</p>
<p>When the singular values are assigned totally to the left or to the right factor, the resultant coordinates are called <em>principal coordinates</em> and the sum of squared coordinates on each dimension equal the corresponding singular value. The other matrix, to which no part of the singular values is assigned, contains the so-called <em>standard coordinates</em> and have sum of squared values equal to 1.0.</p>
</section><section id="biplots-in-r" class="level3" data-number="4.3.2"><h3 data-number="4.3.2" class="anchored" data-anchor-id="biplots-in-r">
<span class="header-section-number">4.3.2</span> Biplots in R</h3>
<p>There are a large number of R packages providing biplots. The most basic, <code><a href="https://rdrr.io/r/stats/biplot.html">stats::biplot()</a></code>, provides methods for <code>"prcomp"</code> and <code>"princomp"</code> objects.</p>
<p><strong>TODO</strong>: Mention <strong>factoextra</strong> package, <code><a href="https://rdrr.io/pkg/factoextra/man/fviz.html">fviz()</a></code>, <code><a href="https://rdrr.io/pkg/factoextra/man/fviz_pca.html">fviz_pca_biplot()</a></code>, … giving <code>ggplot2</code> graphics. Also mention <strong>adegraphics</strong> package</p>
<p>Here, I use the <strong>ggbiplot</strong> package, which aims to provide a simple interface to biplots within the <code>ggplot2</code> framework.</p>
</section><section id="example" class="level3" data-number="4.3.3"><h3 data-number="4.3.3" class="anchored" data-anchor-id="example">
<span class="header-section-number">4.3.3</span> Example</h3>
<p>A basic biplot of the <code>crime</code> data, using standardized principal components and labeling the observation by their state abbreviation is shown in <a href="#fig-crime-biplot1">Figure&nbsp;<span>4.11</span></a>. The correlation circle indicates that these components are uncorrelated and have equal variance in the display.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">crime.pca</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/reflect.html">reflect</a></span><span class="op">(</span><span class="va">crime.pca</span><span class="op">)</span> <span class="co"># reflect the axes</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/ggbiplot.html">ggbiplot</a></span><span class="op">(</span><span class="va">crime.pca</span>,</span>
<span>   obs.scale <span class="op">=</span> <span class="fl">1</span>, var.scale <span class="op">=</span> <span class="fl">1</span>,</span>
<span>   labels <span class="op">=</span> <span class="va">crime</span><span class="op">$</span><span class="va">st</span> ,</span>
<span>   circle <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>   varname.size <span class="op">=</span> <span class="fl">4</span>,</span>
<span>   varname.color <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-crime-biplot1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-crime-biplot1-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.11: Basic biplot of the crime data. …</figcaption></figure>
</div>
</div>
</div>
<p>In this dataset the states are grouped by region and we saw some differences among regions in the plot (<a href="#fig-crime-scores-plot12">Figure&nbsp;<span>4.8</span></a>) of component scores. <code><a href="https://rdrr.io/pkg/ggbiplot/man/ggbiplot.html">ggbiplot()</a></code> provides options to include a <code>groups =</code> variable, used to color the observation points and also to draw their data ellipses, facilitating interpretation.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/ggbiplot.html">ggbiplot</a></span><span class="op">(</span><span class="va">crime.pca</span>,</span>
<span>   obs.scale <span class="op">=</span> <span class="fl">1</span>, var.scale <span class="op">=</span> <span class="fl">1</span>,</span>
<span>   groups <span class="op">=</span> <span class="va">crime</span><span class="op">$</span><span class="va">region</span>,</span>
<span>   labels <span class="op">=</span> <span class="va">crime</span><span class="op">$</span><span class="va">st</span>,</span>
<span>   labels.size <span class="op">=</span> <span class="fl">4</span>,</span>
<span>   var.factor <span class="op">=</span> <span class="fl">1.4</span>,</span>
<span>   ellipse <span class="op">=</span> <span class="cn">TRUE</span>, ellipse.level <span class="op">=</span> <span class="fl">0.5</span>, ellipse.alpha <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>   circle <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>   varname.size <span class="op">=</span> <span class="fl">4</span>,</span>
<span>   varname.color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"Region"</span>, color <span class="op">=</span> <span class="st">"Region"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.direction <span class="op">=</span> <span class="st">'horizontal'</span>, legend.position <span class="op">=</span> <span class="st">'top'</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-crime-biplot2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-crime-biplot2-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.12: Enhanced biplot of the crime data, grouping the states by region and adding data ellipses.</figcaption></figure>
</div>
</div>
</div>
<p>This plot provides what is necessary to interpret the nature of the components and also the variation of the states in relation to these. In this, the data ellipses for the regions provide a visual summary that aids interpretation.</p>
<ul>
<li><p>From the variable vectors, it seems that PC1, having all positive and nearly equal loadings, reflects a total or overall index of crimes. Nevada, California, New York and Florida are highest on this, while North Dakota, South Dakota and West Virginia are lowest.</p></li>
<li><p>The second component, PC2, shows a contrast between crimes against persons (murder, assault, rape) at the top and property crimes (auto theft, larceny) at the bottom. Nearly all the Southern states are high on personal crimes; states in the North East are generally higher on property crimes.</p></li>
<li><p>Western states tend to be somewhat higher on overall crime rate, while North Central are lower on average. In these states there is not much variation in the relative proportions of personal vs.&nbsp;property crimes.</p></li>
</ul>
<p>Moreover, in this biplot you can interpret the the value for a particular state on a given crime by considering its projection on the variable vector, where the origin corresponds to the mean, positions along the vector have greater than average values on that crime, and the opposite direction have lower than average values. For example, Massachusetts has the highest value on auto theft, but a value less than the mean. Louisiana and South Carolina on the other hand are highest in the rate of murder and slightly less than average on auto theft.</p>
<p>These 2D plots account for only 76.5% of the total variance of crimes, so it is useful to also examine the third principal component, which accounts for an additional 10.4%. The <code>choices =</code> option controls which dimensions are plotted.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/ggbiplot.html">ggbiplot</a></span><span class="op">(</span><span class="va">crime.pca</span>,</span>
<span>         choices <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">3</span><span class="op">)</span>,</span>
<span>         obs.scale <span class="op">=</span> <span class="fl">1</span>, var.scale <span class="op">=</span> <span class="fl">1</span>,</span>
<span>         groups <span class="op">=</span> <span class="va">crime</span><span class="op">$</span><span class="va">region</span>,</span>
<span>         labels <span class="op">=</span> <span class="va">crime</span><span class="op">$</span><span class="va">st</span>,</span>
<span>         labels.size <span class="op">=</span> <span class="fl">4</span>,</span>
<span>         var.factor <span class="op">=</span> <span class="fl">2</span>,</span>
<span>         ellipse <span class="op">=</span> <span class="cn">TRUE</span>, ellipse.level <span class="op">=</span> <span class="fl">0.5</span>, ellipse.alpha <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>         circle <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>         varname.size <span class="op">=</span> <span class="fl">4</span>,</span>
<span>         varname.color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"Region"</span>, color <span class="op">=</span> <span class="st">"Region"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.direction <span class="op">=</span> <span class="st">'horizontal'</span>, legend.position <span class="op">=</span> <span class="st">'top'</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-crime-biplot3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-crime-biplot3-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.13: Biplot of dimensions 1 &amp; 3 of the crime data, with data ellipses for the regions.</figcaption></figure>
</div>
</div>
</div>
<p>Dimension 3 in <a href="#fig-crime-biplot3">Figure&nbsp;<span>4.13</span></a> is more subtle. One interpretation is a contrast between larceny, which is a larceny (simple theft) and robbery, which involves stealing something from a person and is considered a more serious crime with an element of possible violence. In this plot, murder has a relatively short variable vector, so does not contribute very much to differences among the states.</p>
</section><section id="biplot-contributions-and-quality" class="level3" data-number="4.3.4"><h3 data-number="4.3.4" class="anchored" data-anchor-id="biplot-contributions-and-quality">
<span class="header-section-number">4.3.4</span> Biplot contributions and quality</h3>
<p>To better understand how much each variable contributes to the biplot dimensions, it is helpful to see information about the variance of variables along each dimension. Graphically, this is nothing more than a measure of the lengths of projections of the variables on each of the dimensions. <code><a href="https://rdrr.io/pkg/factoextra/man/get_pca.html">factoextra::get_pca_var()</a></code> calculates a number of tables from a <code>"prcomp"</code> or similar object.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">var_info</span> <span class="op">&lt;-</span> <span class="fu">factoextra</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/get_pca.html">get_pca_var</a></span><span class="op">(</span><span class="va">crime.pca</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">var_info</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "coord"   "cor"     "cos2"    "contrib"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The component <code>cor</code> gives correlations of the variables with the dimensions and <code>contrib</code> gives their variance contributions as percents, where each row and column sums to 100.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">contrib</span> <span class="op">&lt;-</span> <span class="va">var_info</span><span class="op">$</span><span class="va">contrib</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">contrib</span>, Total <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">contrib</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span>Total <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colSums</a></span><span class="op">(</span><span class="va">contrib</span><span class="op">)</span>, <span class="cn">NA</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span>digits<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt;           Dim.1  Dim.2  Dim.3  Dim.4  Dim.5  Dim.6  Dim.7 Total</span></span>
<span><span class="co">#&gt; murder     9.02  39.59   3.18   5.39  28.96   6.71   7.16   100</span></span>
<span><span class="co">#&gt; rape      18.64   2.87   5.96   0.39   3.55  59.79   8.79   100</span></span>
<span><span class="co">#&gt; robbery   15.75   0.18  24.59  31.14  27.04   1.31   0.00   100</span></span>
<span><span class="co">#&gt; assault   15.73  11.80   0.48  39.67  25.67   2.97   3.68   100</span></span>
<span><span class="co">#&gt; burglary  19.37   4.13   4.41   0.33   1.02  28.73  42.01   100</span></span>
<span><span class="co">#&gt; larceny   12.77  16.19  29.08   5.52   0.09   0.16  36.20   100</span></span>
<span><span class="co">#&gt; auto       8.71  25.24  32.31  17.58  13.67   0.33   2.16   100</span></span>
<span><span class="co">#&gt; Total    100.00 100.00 100.00 100.00 100.00 100.00 100.00    NA</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>These contributions can be visualized as sorted barcharts for a given axis using <code><a href="https://rdrr.io/pkg/factoextra/man/fviz_contrib.html">factoextra::fviz_contrib()</a></code>. The dashed horizontal lines are at the average value for each dimension.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_contrib.html">fviz_contrib</a></span><span class="op">(</span><span class="va">crime.pca</span>, choice <span class="op">=</span> <span class="st">"var"</span>, axes <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                   fill <span class="op">=</span> <span class="st">"lightgreen"</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_contrib.html">fviz_contrib</a></span><span class="op">(</span><span class="va">crime.pca</span>, choice <span class="op">=</span> <span class="st">"var"</span>, axes <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                   fill <span class="op">=</span> <span class="st">"lightgreen"</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span>
<span><span class="va">p1</span> <span class="op">+</span> <span class="va">p2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-fviz-contrib" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-fviz-contrib-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.14: Contributions of the crime variables to dimensions 1 (left) &amp; 2 (right) of the PCA solution</figcaption></figure>
</div>
</div>
</div>
<p>A simple rubric for interpreting the dimensions in terms of the variable contributions is to mention those that are largest or above average on each dimension. So, burglary and rape contribute most to the first dimension, while murder and auto theft contribute most to the second.</p>
<p>Another useful measure is called <code>cos2</code>, the <em>quality</em> of representation, meaning how much of a variable is represented in a given component. The columns sum to the eigenvalue for each dimension. The rows each sum to 1.0, meaning each variable is completely represented on all components, but we can find the quality of a <span class="math inline">\(k\)</span>-D solution by summing the values in the first <span class="math inline">\(k\)</span> columns. These can be plotted in a style similar to <a href="#fig-fviz-contrib">Figure&nbsp;<span>4.14</span></a> using <code><a href="https://rdrr.io/pkg/factoextra/man/fviz_cos2.html">factoextra::fviz_cos2()</a></code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">quality</span> <span class="op">&lt;-</span> <span class="va">var_info</span><span class="op">$</span><span class="va">cos2</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">quality</span><span class="op">)</span></span>
<span><span class="co">#&gt;   murder     rape  robbery  assault burglary  larceny     auto </span></span>
<span><span class="co">#&gt;        1        1        1        1        1        1        1</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colSums</a></span><span class="op">(</span><span class="va">quality</span><span class="op">)</span></span>
<span><span class="co">#&gt; Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 Dim.6 Dim.7 </span></span>
<span><span class="co">#&gt; 4.115 1.239 0.726 0.316 0.258 0.222 0.124</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">quality</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, </span>
<span>      Total <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">quality</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt;          Dim.1 Dim.2 Total</span></span>
<span><span class="co">#&gt; murder    0.37  0.49  0.86</span></span>
<span><span class="co">#&gt; rape      0.77  0.04  0.80</span></span>
<span><span class="co">#&gt; robbery   0.65  0.00  0.65</span></span>
<span><span class="co">#&gt; assault   0.65  0.15  0.79</span></span>
<span><span class="co">#&gt; burglary  0.80  0.05  0.85</span></span>
<span><span class="co">#&gt; larceny   0.53  0.20  0.73</span></span>
<span><span class="co">#&gt; auto      0.36  0.31  0.67</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In two dimensions, murder and burglary are best represented; robbery and larceny are the worst, but as we saw above (<a href="#fig-crime-biplot3">Figure&nbsp;<span>4.13</span></a>), these crimes are implicated in the third dimension.</p>
</section><section id="sec-supp-vars" class="level3" data-number="4.3.5"><h3 data-number="4.3.5" class="anchored" data-anchor-id="sec-supp-vars">
<span class="header-section-number">4.3.5</span> Supplementary variables</h3>
<p>An important feature of biplot methodology is that once you have a reduced-rank display of the relations among a set of variables, you can use other available data to help interpret what what is shown in the biplot. In a sense, this is what I did above in <a href="#fig-crime-biplot2">Figure&nbsp;<span>4.12</span></a> and <a href="#fig-crime-biplot3">Figure&nbsp;<span>4.13</span></a> using <code>region</code> as a grouping variable and summarizing the variability in the scores for states with their data ellipses by region.</p>
<p>When we have other quantitative variables on the same observations, these can be represented as supplementary variables in the same space, by what amounts to regressions of these new variables on the principal component dimensions. For example, the left panel of <a href="#fig-supp-regession">Figure&nbsp;<span>4.15</span></a> depicts the vector geometry of a regression of a variable <span class="math inline">\(\mathbf{y}\)</span> on two predictors, <span class="math inline">\(\mathbf{x}_1\)</span> and <span class="math inline">\(\mathbf{x}_2\)</span>. The fitted vector, <span class="math inline">\(\widehat{\mathbf{y}}\)</span>, is the perpendicular projection of <span class="math inline">\(\mathbf{y}\)</span> onto the plane of <span class="math inline">\(\mathbf{x}_1\)</span> and <span class="math inline">\(\mathbf{x}_2\)</span>. In the same way, in the right panel the supplementary variable is projected into the plane of two principal component axes.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-supp-regession" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/pca4ds-figure-2-11.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.15: Fitting supplementary variables in a biplot is analogous to regression on the principal component dimensions. <em>Source</em>: <span class="citation" data-cites="Aluja-etal-2018">Aluja et al. (<a href="90-references.html#ref-Aluja-etal-2018" role="doc-biblioref">2018</a>)</span>, Figure 2.11</figcaption></figure>
</div>
</div>
</div>
<p>For this example, it happens that some suitable supplementary variables to aid interpretation of crime rates are available in the dataset <code>datsets::state.x77</code>, which was obtained from the U.S. Bureau of the Census <em>Statistical Abstract of the United States</em> for 1977. I select a few of these below and make the state name a column variable so it can be merged with the <code>crime</code> data.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">supp_data</span> <span class="op">&lt;-</span> <span class="va">state.x77</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/rownames.html">rownames_to_column</a></span><span class="op">(</span>var <span class="op">=</span> <span class="st">"state"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">state</span>, <span class="va">Income</span><span class="op">:</span><span class="va">`Life Exp`</span>, <span class="va">`HS Grad`</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/rename.html">rename</a></span><span class="op">(</span>Life_Exp <span class="op">=</span> <span class="va">`Life Exp`</span>,</span>
<span>         HS_Grad <span class="op">=</span> <span class="va">`HS Grad`</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">supp_data</span><span class="op">)</span></span>
<span><span class="co">#&gt;        state Income Illiteracy Life_Exp HS_Grad</span></span>
<span><span class="co">#&gt; 1    Alabama   3624        2.1     69.0    41.3</span></span>
<span><span class="co">#&gt; 2     Alaska   6315        1.5     69.3    66.7</span></span>
<span><span class="co">#&gt; 3    Arizona   4530        1.8     70.5    58.1</span></span>
<span><span class="co">#&gt; 4   Arkansas   3378        1.9     70.7    39.9</span></span>
<span><span class="co">#&gt; 5 California   5114        1.1     71.7    62.6</span></span>
<span><span class="co">#&gt; 6   Colorado   4884        0.7     72.1    63.9</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, we can merge the <code>crime</code> data with the <code>supp_data</code> dataset to produce something suitable for analysis using <code>factoMineR::PCA()</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">crime_joined</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate-joins.html">left_join</a></span><span class="op">(</span><span class="va">crime</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">8</span><span class="op">]</span>, <span class="va">supp_data</span>, by <span class="op">=</span> <span class="st">"state"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">crime_joined</span><span class="op">)</span></span>
<span><span class="co">#&gt;  [1] "state"      "murder"     "rape"       "robbery"   </span></span>
<span><span class="co">#&gt;  [5] "assault"    "burglary"   "larceny"    "auto"      </span></span>
<span><span class="co">#&gt;  [9] "Income"     "Illiteracy" "Life_Exp"   "HS_Grad"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code><a href="https://rdrr.io/pkg/FactoMineR/man/PCA.html">PCA()</a></code> can only get the labels for the observations from the <code><a href="https://rdrr.io/r/base/row.names.html">row.names()</a></code> of the dataset, so I assign them explicitly. The supplementary variables are specified by the argument <code>quanti.sup</code> as the indices of the columns in what is passed as the data argument.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/row.names.html">row.names</a></span><span class="op">(</span><span class="va">crime_joined</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">crime</span><span class="op">$</span><span class="va">st</span></span>
<span><span class="va">crime.PCA_sup</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/FactoMineR/man/PCA.html">PCA</a></span><span class="op">(</span><span class="va">crime_joined</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">8</span>, <span class="fl">9</span><span class="op">:</span><span class="fl">12</span><span class="op">)</span><span class="op">]</span>, </span>
<span>                     quanti.sup <span class="op">=</span> <span class="fl">8</span><span class="op">:</span><span class="fl">11</span>,</span>
<span>                     scale.unit<span class="op">=</span><span class="cn">TRUE</span>, </span>
<span>                     ncp<span class="op">=</span><span class="fl">5</span>, </span>
<span>                     graph <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The essential difference between the result of <code><a href="https://rdrr.io/r/stats/prcomp.html">prcomp()</a></code> used earlier to get the <code>crime.pca</code> object and the result of <code><a href="https://rdrr.io/pkg/FactoMineR/man/PCA.html">PCA()</a></code> with supplementary variables is that the <code>crime.PCA_sup</code> object now contains a <code>quanti.sup</code> component containing the coordinates for the supplementary variables. This can be plotted using <code>FactoMiner::plot()</code> or various <code>factoextra</code> functions like <code><a href="https://rdrr.io/pkg/factoextra/man/fviz_pca.html">fviz_pca_var()</a></code> for a plot of the variable vectors or <code><a href="https://rdrr.io/pkg/factoextra/man/fviz_pca.html">fviz_pca_biplot()</a></code> for a biplot. When a <code>quanti.sup</code> component is present, supplementary variables are also shown in the displays.</p>
<p>For simplicity I use <code>FactoMiner::plot()</code> here and only show the variable vectors. For consistency with earlier plots, I reflect the orientation of the 2nd PCA dimension so that crimes of personal violence are at the top, as in <a href="#fig-crime-vectors">Figure&nbsp;<span>4.9</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># reverse coordinates of Dim 2</span></span>
<span><span class="va">crime.PCA_sup</span> <span class="op">&lt;-</span> <span class="fu">ggbiplot</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/reflect.html">reflect</a></span><span class="op">(</span><span class="va">crime.PCA_sup</span>, columns <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co"># also reverse the orientation of coordinates for supplementary vars on Dim 2</span></span>
<span><span class="va">crime.PCA_sup</span><span class="op">$</span><span class="va">quanti.sup</span><span class="op">$</span><span class="va">coord</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="va">crime.PCA_sup</span><span class="op">$</span><span class="va">quanti.sup</span><span class="op">$</span><span class="va">coord</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">crime.PCA_sup</span>, choix <span class="op">=</span> <span class="st">"var"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-crime-factominer" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-crime-factominer-1.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.16: PCA plot of variables for the crime data, with vectors for the supplementary variables showing their association with the principal component dimensions.</figcaption></figure>
</div>
</div>
</div>
<p>Recall that from earlier analyses, I interpreted the the dominant PC1 dimension as reflecting overall rate of crime. The contributions to this dimension, which are the projections of the variable vectors on the horizontal axis in <a href="#fig-crime-vectors">Figure&nbsp;<span>4.9</span></a> and <a href="#fig-crime-biplot2">Figure&nbsp;<span>4.12</span></a> were shown graphically by barcharts in the left panel of <a href="#fig-fviz-contrib">Figure&nbsp;<span>4.14</span></a>.</p>
<p>But now in <a href="#fig-crime-factominer">Figure&nbsp;<span>4.16</span></a>, with the addition of variable vectors for the supplementary variables, you can see how income, rate of illiteracy, life expectancy and proportion of high school graduates are related to the variation in rates of crimes for the U.S. states.</p>
<p>On dimension 1, what stands out is that life expectancy is associated with lower overall crime, while other supplementary variable have positive associations. On dimension 2, crimes against persons (murder, assault, rape) are associated with greater rates of illiteracy among the states, which as we earlier saw (<a href="#fig-crime-biplot2">Figure&nbsp;<span>4.12</span></a>) were more often Southern states. Crimes against property (auto theft, larceny) at the bottom of this dimension are associated with higher levels of income and high school graduates</p>
</section></section><section id="sec-var-order" class="level2" data-number="4.4"><h2 data-number="4.4" class="anchored" data-anchor-id="sec-var-order">
<span class="header-section-number">4.4</span> Application: Variable ordering for data displays</h2>
<p>In many multivariate data displays, such as scatterplot matrices, parallel coordinate plots and others reviewed in <a href="03-multivariate_plots.html"><span>Chapter&nbsp;3</span></a>, the order of different variables might seem arbitrary. They might appear in alphabetic order, or more often in the order they appear in your dataset, for example when you use <code>pairs(mydata)</code>. Yet, the principle of <em>effect ordering</em> (<span class="citation" data-cites="FriendlyKwan:03:effect">Friendly &amp; Kwan (<a href="90-references.html#ref-FriendlyKwan:03:effect" role="doc-biblioref">2003</a>)</span>) for variables says you should try to arrange the variables so that adjacent ones are as similar as possible.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>For example, the <code>mtcars</code> dataset contains data on 32 automobiles from the 1974 U.S. magazine <em>Motor Trend</em> and consists of fuel comsumption (<code>mpg</code>) and 10 aspects of automobile design (<code>cyl</code>: number of cyliners; <code>hp</code>: horsepower, <code>wt</code>: weight) and performance (<code>qsec</code>: time to drive a quarter-mile). What can we see from a simple <code><a href="https://rdrr.io/pkg/corrplot/man/corrplot.html">corrplot()</a></code> of their correlations?</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/taiyun/corrplot">corrplot</a></span><span class="op">)</span></span>
<span><span class="va">R</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/corrplot/man/corrplot.html">corrplot</a></span><span class="op">(</span><span class="va">R</span>, </span>
<span>         method <span class="op">=</span> <span class="st">'ellipse'</span>,</span>
<span>         title <span class="op">=</span> <span class="st">"Dataset variable order"</span>,</span>
<span>         tl.srt <span class="op">=</span> <span class="fl">0</span>, tl.col <span class="op">=</span> <span class="st">"black"</span>, tl.pos <span class="op">=</span> <span class="st">'d'</span>,</span>
<span>         mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mtcars-corrplot-varorder" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-mtcars-corrplot-varorder-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.17: Corrplot of <code>mtcars</code> data, with the variables in the order they appear in the dataset.</figcaption></figure>
</div>
</div>
</div>
<p>In this display you can scan the rows and columns to “look up” the sign and approximate magnitude of a given correlation; for example, the correlation between <code>mpg</code> and <code>cyl</code> appears to be about -0.9, while that between <code>mpg</code> and <code>gear</code> is about 0.5. Of course, you could print the correlation matrix to find the actual values (-0.86 and 0.48 respectively):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">floor</a></span><span class="op">(</span><span class="fl">100</span><span class="op">*</span><span class="va">R</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      mpg cyl disp  hp drat  wt qsec  vs  am gear carb</span></span>
<span><span class="co">#&gt; mpg  100 -86  -85 -78   68 -87   41  66  59   48  -56</span></span>
<span><span class="co">#&gt; cyl  -86 100   90  83  -70  78  -60 -82 -53  -50   52</span></span>
<span><span class="co">#&gt; disp -85  90  100  79  -72  88  -44 -72 -60  -56   39</span></span>
<span><span class="co">#&gt; hp   -78  83   79 100  -45  65  -71 -73 -25  -13   74</span></span>
<span><span class="co">#&gt; drat  68 -70  -72 -45  100 -72    9  44  71   69  -10</span></span>
<span><span class="co">#&gt; wt   -87  78   88  65  -72 100  -18 -56 -70  -59   42</span></span>
<span><span class="co">#&gt; qsec  41 -60  -44 -71    9 -18  100  74 -23  -22  -66</span></span>
<span><span class="co">#&gt; vs    66 -82  -72 -73   44 -56   74 100  16   20  -57</span></span>
<span><span class="co">#&gt; am    59 -53  -60 -25   71 -70  -23  16 100   79    5</span></span>
<span><span class="co">#&gt; gear  48 -50  -56 -13   69 -59  -22  20  79  100   27</span></span>
<span><span class="co">#&gt; carb -56  52   39  74  -10  42  -66 -57   5   27  100</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Because the angles between variable vectors in the biplot reflect their correlations, <span class="citation" data-cites="FriendlyKwan:03:effect">Friendly &amp; Kwan (<a href="90-references.html#ref-FriendlyKwan:03:effect" role="doc-biblioref">2003</a>)</span> defined <strong>principal component variable ordering</strong> as the order of angles, <span class="math inline">\(a_i\)</span> of the first two eigenvectors, <span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2\)</span> around the unit circle. These values are calculated going counter-clockwise from the 12:00 position as:</p>
<p><span class="math display">\[
a_i =
  \begin{cases}
    \tan^{-1} (v_{i2}/v_{i1}), &amp; \text{if $v_{i1}&gt;0$;}
     \newline
    \tan^{-1} (v_{i2}/v_{i1}) + \pi, &amp; \text{otherwise.}
  \end{cases}     
\]</span> (read <span class="math inline">\(\tan^{-1}(x)\)</span> as “the angle whose tangent is <span class="math inline">\(x\)</span>”.)</p>
<p><strong>TODO</strong>: Make a diagram of this</p>
<p>For the <code>mtcars</code> data the biplot in <a href="#fig-mtcars-biplot">Figure&nbsp;<span>4.18</span></a> accounts for 84% of the total variance so a 2D representation is fairly good. The plot shows the variables as widely dispersed. There is a collection at the left of positively correlated variables and another positively correlated set at the right.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mtcars.pca</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/prcomp.html">prcomp</a></span><span class="op">(</span><span class="va">mtcars</span>, scale. <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/ggbiplot.html">ggbiplot</a></span><span class="op">(</span><span class="va">mtcars.pca</span>,</span>
<span>         circle <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>         point.size <span class="op">=</span> <span class="fl">2.5</span>,</span>
<span>         varname.size <span class="op">=</span> <span class="fl">6</span>,</span>
<span>         varname.color <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mtcars-biplot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-mtcars-biplot-1.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.18: Biplot of the <code>mtcars</code> data …</figcaption></figure>
</div>
</div>
</div>
<p>In <code><a href="https://rdrr.io/pkg/corrplot/man/corrplot.html">corrplot()</a></code> principal component variable ordering is implemented using the <code>order = "AOE"</code> option. There are a variety of other methods based on hierarchical cluster analysis described in the <a href="https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html">package vignette</a>.</p>
<p><a href="#fig-mtcars-corrplot-pcaorder">Figure&nbsp;<span>4.19</span></a> shows the result. A nice feature of <code><a href="https://rdrr.io/pkg/corrplot/man/corrplot.html">corrplot()</a></code> is the ability to manually highlight blocks of variables that have a similar pattern of signs by outlining them with rectangles. From the biplot, the two main clusters of positively correlated variables seemed clear, and are outlined in the plot using <code><a href="https://rdrr.io/pkg/corrplot/man/corrRect.html">corrplot::corrRect()</a></code>. What became clear in the corrplot is that <code>qsec</code>, the time to drive a quarter-mile from a dead start didn’t fit this pattern, so I highlighted it separately.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/corrplot/man/corrplot.html">corrplot</a></span><span class="op">(</span><span class="va">R</span>, </span>
<span>         method <span class="op">=</span> <span class="st">'ellipse'</span>, </span>
<span>         order <span class="op">=</span> <span class="st">"AOE"</span>,</span>
<span>         title <span class="op">=</span> <span class="st">"PCA variable order"</span>,</span>
<span>         tl.srt <span class="op">=</span> <span class="fl">0</span>, tl.col <span class="op">=</span> <span class="st">"black"</span>, tl.pos <span class="op">=</span> <span class="st">'d'</span>,</span>
<span>         mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/corrplot/man/corrRect.html">corrRect</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">6</span>, <span class="fl">7</span>, <span class="fl">11</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mtcars-corrplot-pcaorder" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-mtcars-corrplot-pcaorder-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.19: Corrplot of <code>mtcars</code> data, with the variables ordered according to the variable vectors in the biplot.</figcaption></figure>
</div>
</div>
</div>
<p>But wait, there is something else to be seen in <a href="#fig-mtcars-corrplot-pcaorder">Figure&nbsp;<span>4.19</span></a>. Can you see one cell that doesn’t fit with the rest?</p>
<p>Yes, the correlation of number of forward gears (<code>gear</code>) and number of carburators (<code>carb</code>) in the upper left and lower right corners stands out as moderately positive (0.27) while all the others in their off-diagonal blocks are negative. This is another benefit of effect ordering: when you arrange the variables so that the most highly related variable are together, features that deviate from dominant pattern become visible.</p>
</section><section id="application-eigenfaces" class="level2" data-number="4.5"><h2 data-number="4.5" class="anchored" data-anchor-id="application-eigenfaces">
<span class="header-section-number">4.5</span> Application: Eigenfaces</h2>
<p>There are many applications of principal components analysis beyond the use for visualization for multivariate data covered here, that rely on its’ ability as a <strong>dimension reduction</strong> technique, that is, to find a low-dimensional approximation to a high-dimensional dataset.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Machine learning uses">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Machine learning uses
</div>
</div>
<div class="callout-body-container callout-body">
<p>In machine learning, for example, PCA is a method used to reduce model complexity and avoid overfitting by <em>feature extraction</em>, which amounts to fitting a response variable in a low-D space of the predictors. This is just another name for <em>principal components regression</em>, where, instead of regressing the dependent variable on all the explanatory variables directly, a smaller number principal components of the explanatory variables is used as predictors. This has the added benefit that it avoids problems of collinearity (section-ref) due to high correlations of the predictors, because the principal component scores are necessarily uncorrelated. When the goal is model explanation rather than pure prediction, it has the disadvantage that the components may be hard to interpret.</p>
</div>
</div>
<p>An interesting class of problems have to do with image processing, where an image of size width <span class="math inline">\(\times\)</span> height in pixels can be represented by a <span class="math inline">\(w \times h\)</span> array of greyscale values <span class="math inline">\(x_{ij}\)</span> in the range of [0, 1] or <span class="math inline">\(h \times w \times 3\)</span> array <span class="math inline">\(x_{ijk}\)</span> of (red, green, blue) color values. For example a single <span class="math inline">\(640 \times 640\)</span> photo is comprised of about 400K pixels in B/W and 1200K pixels in color.</p>
<p>The uses here include</p>
<ul>
<li>
<strong>Image compression</strong>: a process applied to a graphics file to minimize its size in bytes for storage or transmission, without degrading image quality below an acceptable threshold</li>
<li>
<strong>image enhancement</strong>: improving the quality of an image, with applications in Computer Vision tasks, remote sensing, and satellite imagery.</li>
<li>
<strong>facial recognition</strong>: classifying or matching a facial image against a large corpus of stored images.</li>
</ul>
<p>When PCA is used on facial images, you can think of the process as generating <strong>eigenfaces</strong>, a representation of the pixels in the image in terms of an eigenvalue decomposition. Dimension reduction means that a facial image can be considerably compressed by removing the components associated with small dimensions.</p>
<p>As an example, consider the black and white version of the Mona Lisa shown in <a href="#fig-MonaLisa">Figure&nbsp;<span>4.20</span></a>. The idea and code for this example is adapted from this <a href="https://kieranhealy.org/blog/archives/2019/10/27/reconstructing-images-using-pca/">blog post</a> by Kieran Healy.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p><strong>TODO</strong>: <del>Web links like this should be footnotes for PDF</del></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-MonaLisa" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/MonaLisa-BW.jpg" class="img-fluid figure-img" style="width:40.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.20: 640 x 954 black and white image of the <em>Mona Lisa</em>. Source: <a href="https://bit.ly/3Rgo41f">Wikipedia</a></figcaption></figure>
</div>
</div>
</div>
<p>It would take too long to explain the entire method, so I’ll just sketch the essential parts here. The complete script for this example is contained in <a href="R/PCA-MonaLisa.R">PCA-MonaLisa.R</a>. …</p>
<p><strong>TODO</strong>: Show the necessary parts, including the screeplot.</p>
<p>An image can be imported using <code><a href="https://rdrr.io/pkg/imager/man/load.image.html">imager::load.image()</a></code> which creates a <code>"cimg"</code> object, a 4-dimensional array with dimensions named <code>x,y,z,c</code>. <code>x</code> and <code>y</code> are the usual spatial dimensions, <code>z</code> is a depth dimension (which would correspond to time in a movie), and <code>c</code> is a color dimension containing R, G, B values.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://asgr.github.io/imager/">imager</a></span><span class="op">)</span></span>
<span><span class="va">img</span> <span class="op">&lt;-</span> <span class="fu">imager</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/imager/man/load.image.html">load.image</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org//reference/here.html">here</a></span><span class="op">(</span><span class="st">"images"</span>, <span class="st">"MonaLisa-BW.jpg"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">img</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 640 954   1   1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!-- img <- imager::load.image("https://github.com/friendly/Vis-MLM-book/blob/master/images/MonaLisa-BW.jpg?raw=true") -->
<p>An <code><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame()</a></code> method converts this to a data frame with <code>x</code> and <code>y</code> coordinates. Each x-y pair is a location in the 640 by 954 pixel grid, and the <code>value</code> is a grayscale value ranging from zero to one.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">img_df_long</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">img</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">img_df_long</span><span class="op">)</span></span>
<span><span class="co">#&gt;   x y value</span></span>
<span><span class="co">#&gt; 1 1 1 0.431</span></span>
<span><span class="co">#&gt; 2 2 1 0.337</span></span>
<span><span class="co">#&gt; 3 3 1 0.467</span></span>
<span><span class="co">#&gt; 4 4 1 0.337</span></span>
<span><span class="co">#&gt; 5 5 1 0.376</span></span>
<span><span class="co">#&gt; 6 6 1 0.361</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>However, to do a PCA we will need a matrix of data in wide format containing the grayscale pixel values. We can do this using <code><a href="https://tidyr.tidyverse.org/reference/pivot_wider.html">tidyr::pivot_wider()</a></code>, giving a result with 640 rows and 954 columns.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb32" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">img_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_wider.html">pivot_wider</a></span><span class="op">(</span><span class="va">img_df_long</span>, </span>
<span>                     names_from <span class="op">=</span> <span class="va">y</span>, </span>
<span>                     values_from <span class="op">=</span> <span class="va">value</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">img_df</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 640 954</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Mona’s PCA is produced from this <code>img_df</code> with <code><a href="https://rdrr.io/r/stats/prcomp.html">prcomp()</a></code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">img_pca</span> <span class="op">&lt;-</span> <span class="va">img_df</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/prcomp.html">prcomp</a></span><span class="op">(</span>scale <span class="op">=</span> <span class="cn">TRUE</span>, center <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With 955 columns, the PCA comprises 955 eigenvalue/eigenvector pairs. However, the rank of a matrix is the smaller of the number of rows and columns, so only 640 eigenvalues can be non-zero. Printing the first 10 shows that the first three dimensions account for 46% of the variance and we only get to 63% with 10 components.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">img_pca</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">broom</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span>matrix <span class="op">=</span> <span class="st">"eigenvalues"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 10 × 4</span></span>
<span><span class="co">#&gt;       PC std.dev percent cumulative</span></span>
<span><span class="co">#&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;</span></span>
<span><span class="co">#&gt;  1     1   14.1  0.209        0.209</span></span>
<span><span class="co">#&gt;  2     2   11.6  0.141        0.350</span></span>
<span><span class="co">#&gt;  3     3   10.1  0.107        0.457</span></span>
<span><span class="co">#&gt;  4     4    7.83 0.0643       0.522</span></span>
<span><span class="co">#&gt;  5     5    6.11 0.0392       0.561</span></span>
<span><span class="co">#&gt;  6     6    4.75 0.0237       0.585</span></span>
<span><span class="co">#&gt;  7     7    3.70 0.0143       0.599</span></span>
<span><span class="co">#&gt;  8     8    3.52 0.0130       0.612</span></span>
<span><span class="co">#&gt;  9     9    3.12 0.0102       0.622</span></span>
<span><span class="co">#&gt; 10    10    2.86 0.00855      0.631</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-mona-screeplot">Figure&nbsp;<span>4.21</span></a> shows a screeplot of proportions of variance. Because there are so many components and most of the information is concentrated in the largest dimensions, I’ve used a <span class="math inline">\(\log_{10}()\)</span> scale on the horizontal axis. Beyond 10 or so dimensions, the variance of additional components looks quite tiny.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/ggscreeplot.html">ggscreeplot</a></span><span class="op">(</span><span class="va">img_pca</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_log10</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mona-screeplot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figs/fig-mona-screeplot-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.21: Screeplot of the variance proportions in the Mona Lisa PCA.</figcaption></figure>
</div>
</div>
</div>
<p>Then, if <span class="math inline">\(\mathbf{M}\)</span> is the <span class="math inline">\(640 \times 955\)</span> matrix of pixel values, a best approximation <span class="math inline">\(\widehat{\mathbf{M}}_k\)</span> using <span class="math inline">\(k\)</span> dimensions can be obtained as <span class="math inline">\(\widehat{\mathbf{M}}_k = \mathbf{X}_k\;\mathbf{V}_k^T\)</span> where <span class="math inline">\(\mathbf{X}_k\)</span> are the principal component scores and <span class="math inline">\(\mathbf{V}_k\)</span> are the eigenvectors corresponding to the <span class="math inline">\(k\)</span> largest eigenvalues. The function <code>approx_pca()</code> does this, and also undoes the scaling and centering carried out in PCA.</p>
<p><strong>TODO</strong>: <del>Also, separate approximation from the pivot_longer code…</del></p>
<div class="cell" data-layout-align="center">
<details><summary>Code</summary><div class="sourceCode" id="cb36" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">approx_pca</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n_comp</span> <span class="op">=</span> <span class="fl">20</span>, <span class="va">pca_object</span> <span class="op">=</span> <span class="va">img_pca</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="co">## Multiply the matrix of rotated data (component scores) by the transpose of </span></span>
<span>  <span class="co">## the matrix of eigenvectors (i.e. the component loadings) to get back to a </span></span>
<span>  <span class="co">## matrix of original data values</span></span>
<span></span>
<span>  <span class="va">recon</span> <span class="op">&lt;-</span> <span class="va">pca_object</span><span class="op">$</span><span class="va">x</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="va">n_comp</span><span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">pca_object</span><span class="op">$</span><span class="va">rotation</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="va">n_comp</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co">## Reverse any scaling and centering that was done by prcomp()</span></span>
<span>  <span class="kw">if</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/all.html">all</a></span><span class="op">(</span><span class="va">pca_object</span><span class="op">$</span><span class="va">scale</span> <span class="op">!=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="co">## Rescale by the reciprocal of the scaling factor, i.e. back to</span></span>
<span>    <span class="co">## original range.</span></span>
<span>    <span class="va">recon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">recon</span>, center <span class="op">=</span> <span class="cn">FALSE</span>, scale <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="va">pca_object</span><span class="op">$</span><span class="va">scale</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="kw">if</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/all.html">all</a></span><span class="op">(</span><span class="va">pca_object</span><span class="op">$</span><span class="va">center</span> <span class="op">!=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="co">## Remove any mean centering by adding the subtracted mean back in</span></span>
<span>    <span class="va">recon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">recon</span>, scale <span class="op">=</span> <span class="cn">FALSE</span>, center <span class="op">=</span> <span class="op">-</span><span class="fl">1</span> <span class="op">*</span> <span class="va">pca_object</span><span class="op">$</span><span class="va">center</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="co">## Make it a data frame that we can easily pivot to long format</span></span>
<span>  <span class="co">## for drawing with ggplot</span></span>
<span>  <span class="va">recon_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">recon</span><span class="op">)</span>, <span class="va">recon</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">recon_df</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">recon_df</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co">## Return the data to long form </span></span>
<span>  <span class="va">recon_df_long</span> <span class="op">&lt;-</span> <span class="va">recon_df</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">tidyr</span><span class="fu">::</span><span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html">pivot_longer</a></span><span class="op">(</span>cols <span class="op">=</span> <span class="op">-</span><span class="va">x</span>, </span>
<span>                        names_to <span class="op">=</span> <span class="st">"y"</span>, </span>
<span>                        values_to <span class="op">=</span> <span class="st">"value"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">recon_df_long</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Finally, the recovered images, using 2, 3 , 4, 5, 10, 15, 20, 50, and 100 principal components can be plotted using ggplot. In the code below, the <code>approx_pca()</code> function is run for each of the 9 values specified by <code>n_pcs</code> giving a data frame <code>recovered_imgs</code> containing all reconstructed images, with variables <code>x</code>, <code>y</code> and <code>value</code> (the greyscale pixel value).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb37" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">n_pcs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">15</span>, <span class="fl">20</span>, <span class="fl">50</span>, <span class="fl">100</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">n_pcs</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"First"</span>, <span class="va">n_pcs</span>, <span class="st">"Components"</span>, sep <span class="op">=</span> <span class="st">"_"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">recovered_imgs</span> <span class="op">&lt;-</span> <span class="fu">map_dfr</span><span class="op">(</span><span class="va">n_pcs</span>, </span>
<span>                          <span class="va">approx_pca</span>, </span>
<span>                          .id <span class="op">=</span> <span class="st">"pcs"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>pcs <span class="op">=</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_replace.html">str_replace_all</a></span><span class="op">(</span><span class="va">pcs</span>, <span class="st">"_"</span>, <span class="st">" "</span><span class="op">)</span>, </span>
<span>         pcs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">pcs</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">pcs</span><span class="op">)</span>, ordered <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In <code><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot()</a></code>, each is plotted using <code><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html">geom_raster()</a></code>, using <code>value</code> to as the fill color. A quirk of images imported to R is that origin is taken as the upper left corner, so the Y axis scale needs to be reversed. The 9 images are then plotted together using <code><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap()</a></code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb38" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">recovered_imgs</span>, </span>
<span>            mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, fill <span class="op">=</span> <span class="va">value</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">p_out</span> <span class="op">&lt;-</span> <span class="va">p</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html">geom_raster</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_reverse</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_gradient.html">scale_fill_gradient</a></span><span class="op">(</span>low <span class="op">=</span> <span class="st">"black"</span>, high <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">pcs</span>, ncol <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/guides.html">guides</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Recovering Mona Lisa from PCA of her pixels"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>strip.text <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>face <span class="op">=</span> <span class="st">"bold"</span>, size <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">rel</a></span><span class="op">(</span><span class="fl">1.2</span><span class="op">)</span><span class="op">)</span>,</span>
<span>        plot.title <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">rel</a></span><span class="op">(</span><span class="fl">1.5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_out</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The result, in <a href="#fig-mona-pca">Figure&nbsp;<span>4.22</span></a> is instructive about how much visual information is contained in lower-dimensional reconstructions, or conversely, how much the image can be compressed by omitting the many small dimensions.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-mona-pca" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/mona-pca.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.22: Re-construction of the Mona Lisa using 2, 3 , 4, 5, 10, 15, 20, 50, and 100 principal components.</figcaption></figure>
</div>
</div>
</div>
<p>In this figure, with 4-5 components most people would recognize this as a blury image of the world’s most famous portrait. It is certainly clear that this is the Mona Lisa with 10–15 components. Details of the portrait and backgound features become recognizable with 20–50 components, and with 100 components it compares favorably with the original in <a href="#fig-MonaLisa">Figure&nbsp;<span>4.20</span></a>. In numbers, the original <span class="math inline">\(640 \times 955\)</span>) image is of size 600 Kb. The 100 component version is only 93 Kb, 15.6% of this.</p>
</section><section id="elliptical-insights-outlier-detection" class="level2" data-number="4.6"><h2 data-number="4.6" class="anchored" data-anchor-id="elliptical-insights-outlier-detection">
<span class="header-section-number">4.6</span> Elliptical insights: Outlier detection</h2>
<p>The data ellipse (<a href="03-multivariate_plots.html#sec-data-ellipse"><span>Section&nbsp;3.1.4</span></a>), or ellipsoid in more than 2D is fundamental in regression. But also, as Pearson showed, it is key to understanding principal components analysis, where the principal component directions are simply the axes of the ellipsoid of the data. As such, observations that are unusual in data space may not stand out in univariate views of the variables, but will stand out in principal component space, usually on the <em>smallest</em> dimension.</p>
<p>As an illustration, I created a dataset of <span class="math inline">\(n = 100\)</span> observations with a linear relation, <span class="math inline">\(y = x + \mathcal{N}(0, 1)\)</span> and then added two discrepant points at (1.5, -1.5), (-1.5, 1.5).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb39" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123345</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>,             <span class="fl">1.5</span>, <span class="op">-</span><span class="fl">1.5</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">100</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>, <span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>When these are plotted with a data ellipse in <a href="#fig-outlier-demo">Figure&nbsp;<span>4.23</span></a> (left), you can see the discrepant points labeled 101 and 102, but they do not stand out as unusual on either <span class="math inline">\(x\)</span> or <span class="math inline">\(y\)</span>. The transformation to from data space to principal components space, shown in <a href="#fig-outlier-demo">Figure&nbsp;<span>4.23</span></a> (right), is simply a rotation of <span class="math inline">\((x, y)\)</span> to a space whose coordinate axes are the major and minor axes of the data ellipse, <span class="math inline">\((PC_1, PC_2)\)</span>. In this view, the additional points appear a univariate outliers on the smallest dimension, <span class="math inline">\(PC_2\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-outlier-demo" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/outlier-demo.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.23: <strong>Outlier demonstration</strong>: The left panel shows the original data and highlights the two discrepant points, which do not appear to be unusual on either x or y. The right panel shows the data rotated to principal components, where the labeled points stand out on the smallest PCA dimension.</figcaption></figure>
</div>
</div>
</div>
<p>To see this more clearly, <a href="#fig-outlier-animation">Figure&nbsp;<span>4.24</span></a> shows an animation of the rotation from data space to PCA space. This uses <code><a href="https://friendly.github.io/heplots/reference/interpPlot.html">heplots::interpPlot()</a></code> …</p>
<div id="fig-outlier-animation" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><div data-align="center">
<p><iframe width="480" height="480" src="images/outlier-demo.gif"></iframe></p>
</div>
<figcaption class="figure-caption">Figure&nbsp;4.24: Animation of rotation from data space to PCA space.</figcaption></figure>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list" style="display: none">
<div id="ref-Aluja-etal-2018" class="csl-entry" role="listitem">
Aluja, T., Morineau, A., &amp; Sanchez, G. (2018). <em>Principal component analysis for data science</em>. <a href="https://pca4ds.github.io/">https://pca4ds.github.io/</a>
</div>
<div id="ref-Cattell1966" class="csl-entry" role="listitem">
Cattell, R. B. (1966). The scree test for the number of factors. <em>Multivariate Behavioral Research</em>, <em>1</em>(2), 245–276. <a href="https://doi.org/10.1207/s15327906mbr0102_10">https://doi.org/10.1207/s15327906mbr0102_10</a>
</div>
<div id="ref-Euler:1758" class="csl-entry" role="listitem">
Euler, L. (1758). Elementa doctrinae solidorum. <em>Novi Commentarii Academiae Scientiarum Petropolitanae</em>, <em>4</em>, 109–140. <a href="https://scholarlycommons.pacific.edu/euler-works/230/">https://scholarlycommons.pacific.edu/euler-works/230/</a>
</div>
<div id="ref-FriendlyKwan:03:effect" class="csl-entry" role="listitem">
Friendly, M., &amp; Kwan, E. (2003). Effect ordering for data displays. <em>Computational Statistics and Data Analysis</em>, <em>43</em>(4), 509–539. <a href="https://doi.org/10.1016/S0167-9473(02)00290-6">https://doi.org/10.1016/S0167-9473(02)00290-6</a>
</div>
<div id="ref-FriendlyMeyer:2016:DDAR" class="csl-entry" role="listitem">
Friendly, M., &amp; Meyer, D. (2016). <em>Discrete data analysis with <span>R</span>: Visualization and modeling techniques for categorical and count data</em>. Chapman &amp; Hall/CRC.
</div>
<div id="ref-Friendly-etal:ellipses:2013" class="csl-entry" role="listitem">
Friendly, M., Monette, G., &amp; Fox, J. (2013). Elliptical insights: Understanding statistical methods through elliptical geometry. <em>Statistical Science</em>, <em>28</em>(1), 1–39. <a href="https://doi.org/10.1214/12-STS402">https://doi.org/10.1214/12-STS402</a>
</div>
<div id="ref-FriendlyWainer:2021:TOGS" class="csl-entry" role="listitem">
Friendly, M., &amp; Wainer, H. (2021). <em>A history of data visualization and graphic communication</em>. Harvard University Press. <a href="https://doi.org/10.4159/9780674259034">https://doi.org/10.4159/9780674259034</a>
</div>
<div id="ref-Gabriel:71" class="csl-entry" role="listitem">
Gabriel, K. R. (1971). The biplot graphic display of matrices with application to principal components analysis. <em>Biometrics</em>, <em>58</em>(3), 453–467. <a href="https://doi.org/10.2307/2334381">https://doi.org/10.2307/2334381</a>
</div>
<div id="ref-Gabriel:81" class="csl-entry" role="listitem">
Gabriel, K. R. (1981). Biplot display of multivariate matrices for inspection of data and diagnosis. In V. Barnett (Ed.), <em>Interpreting multivariate data</em> (pp. 147–173). John Wiley; Sons.
</div>
<div id="ref-Galton:1886" class="csl-entry" role="listitem">
Galton, F. (1886). Regression towards mediocrity in hereditary stature. <em>Journal of the Anthropological Institute</em>, <em>15</em>, 246–263. <a href="http://www.jstor.org/cgi-bin/jstor/viewitem/09595295/dm995266/99p0374f/0">http://www.jstor.org/cgi-bin/jstor/viewitem/09595295/dm995266/99p0374f/0</a>
</div>
<div id="ref-GowerHand:96" class="csl-entry" role="listitem">
Gower, J. C., &amp; Hand, D. J. (1996). <em>Biplots</em>. Chapman &amp; Hall.
</div>
<div id="ref-Gower-etal:2011" class="csl-entry" role="listitem">
Gower, J. C., Lubbe, S. G., &amp; Roux, N. J. L. (2011). <em>Understanding biplots</em>. Wiley. <a href="http://books.google.ca/books?id=66gQCi5JOKYC">http://books.google.ca/books?id=66gQCi5JOKYC</a>
</div>
<div id="ref-Greenacre:84" class="csl-entry" role="listitem">
Greenacre, M. (1984). <em>Theory and applications of correspondence analysis</em>. Academic Press.
</div>
<div id="ref-Greenacre:2010:biplots" class="csl-entry" role="listitem">
Greenacre, M. (2010). <em>Biplots in practice</em>. Fundaci<span>ó</span>n BBVA. <a href="https://books.google.ca/books?id=dv4LrFP7U%5C_EC">https://books.google.ca/books?id=dv4LrFP7U\_EC</a>
</div>
<div id="ref-R-seriation" class="csl-entry" role="listitem">
Hahsler, M., Buchta, C., &amp; Hornik, K. (2023). <em>Seriation: Infrastructure for ordering objects using seriation</em>. <a href="https://github.com/mhahsler/seriation">https://github.com/mhahsler/seriation</a>
</div>
<div id="ref-R-FactoMineR" class="csl-entry" role="listitem">
Husson, F., Josse, J., Le, S., &amp; Mazet, J. (2023). <em>FactoMineR: Multivariate exploratory data analysis and data mining</em>. <a href="http://factominer.free.fr">http://factominer.free.fr</a>
</div>
<div id="ref-Husson-etal-2017" class="csl-entry" role="listitem">
Husson, F., Le, S., &amp; Pagès, J. (2017). <em>Exploratory multivariate analysis by example using r</em>. Chapman &amp; Hall. <a href="https://doi.org/10.1201/b21874">https://doi.org/10.1201/b21874</a>
</div>
<div id="ref-Pearson:1896" class="csl-entry" role="listitem">
Pearson, K. (1896). Contributions to the mathematical theory of evolution—<span>III</span>, regression, heredity and panmixia. <em>Philosophical Transactions of the Royal Society of London</em>, <em>187</em>, 253–318.
</div>
<div id="ref-Pearson:1901" class="csl-entry" role="listitem">
Pearson, K. (1901). On lines and planes of closest fit to systems of points in space. <em>Philosophical Magazine</em>, <em>6</em>(2), 559–572.
</div>
</div>
</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>This is Euler’s <span class="citation" data-cites="Euler:1758">(<a href="90-references.html#ref-Euler:1758" role="doc-biblioref">1758</a>)</span> formula, which states that any convex polyheron must obey the formula <span class="math inline">\(V + F - E = 2\)</span> where <span class="math inline">\(V\)</span> is the number of vertexes (corners), <span class="math inline">\(F\)</span> is the number of faces and <span class="math inline">\(E\)</span> is the number of edges. For example, a tetrahedron or pyramid has <span class="math inline">\((V, F, E) = (4, 4, 6)\)</span> and a cube has <span class="math inline">\((V, F, E) = (8, 6, 12)\)</span>. Stated in words, for all solid bodies confined by planes, the sum of the number of vertexes and the number of faces is two less than the number of edges.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>For example, if two variables in the analysis are height and weight, changing the unit of height from inches to centimeters would multiply its’ variance by <span class="math inline">\(2.54^2\)</span>; changing weight from pounds to kilograms would divide its’ variance by <span class="math inline">\(2.2^2\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The general topic of arranging items (variables, factor values) in an orderly sequence is called <em>seriation</em>, and stems from methods of dating in archaeology, used to arrange stone tools, pottery fragments, and other artifacts in time order. In R, the <strong>seriation</strong> package <span class="citation" data-cites="R-seriation">(<a href="90-references.html#ref-R-seriation" role="doc-biblioref">Hahsler et al., 2023</a>)</span> provides a wide range of techniques. …<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>https://kieranhealy.org/blog/archives/2019/10/27/reconstructing-images-using-pca/<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./03-multivariate_plots.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Plots of Multivariate Data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./linear_models.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Overview of Linear models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<script src="site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>