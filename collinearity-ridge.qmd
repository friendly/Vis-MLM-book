```{r include=FALSE}
source("R/common.R")
```
# Other topics: Multicollinearity & ridge regression

## Visualizing multicolinearity

In regression models, we usually hope to have high correlations between the outcome $y$ and each of the
predictors, $x_1, x_2, \dots$, but high correlations _among_ the predictors can cause problems
in estimating and testing their effects. In the limiting case, when one $x_i$ is _perfectly_
predictable from the other $x$s, i.e., $R^2 (x_i | \text{other }x) = 1$, 

* there is no _unique_ solution for the regression coefficients 
$\mathbf{b} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X} \mathbf{y}$;
* the standard errors $s (b_i)$ of the estimated coefficients are infinite and _t_ statistics $t_i = b_i / s (b_i)$
are 0.

This extreme case reflects a situation when one or more predictors are effectively redundant.
For example, if 

## Generalized ridge trace plots



```{r}
#| echo: false
cat("Writing packages to ", .pkg_file, "\n")
write_pkgs(file = .pkg_file)
```

## References {.unnumbered}
