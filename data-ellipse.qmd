### The Data Ellipse

The _data ellipse_ [@Monette:90], or _concentration ellipse_ [@Dempster:69] is a
remarkably simple and effective display for viewing and understanding
bivariate relationships in multivariate data.
The data ellipse is typically used to add a visual summary to a scatterplot,
that shows all together the means, standard deviations, correlation,
and slope of the regression line for
two variables. 
Under the classical assumption that the data are bivariate normally distributed,
the data ellipse is also a _sufficient visual summary_, in the sense that
it captures all relevant features of the data.
See @Friendly-etal:ellipses:2013 for a complete discussion of the role of
ellipsoids in statistical data visualization.

It is based on the idea that in a bivariate normal distribution, the contours
of equal probability form a series of concentric ellipses. If the variables were
uncorrelated and had the same variances, these would be circles, and Euclidean
distance would measure the distance of each observation from the mean.
When the variables are correlated, a different measure, _Mahalanobis distance_
is the proper measure of how far a point is from the mean.

```{r}
#| label: fig-mahalanobis
#| echo: false
#| fig-align: center
#| out-width: "50%"
#| fig-cap: "2D data with curves of constant distance from the centroid. Which of the points A and B is further from the mean (X)? _Source_: [Ou Zhang](https://ouzhang.rbind.io/2020/11/16/outliers-part4/)"
knitr::include_graphics("images/mahalanobis.png")
```

To illustrate, @fig-mahanalobis shows a scatterplot with labels for two points, "A" and "B".
Which is further from the mean, "X"? 
A contour of constant Euclidean distance, shown by the red dashed circle,
ignores the apparent negative correlation, so point "A" is further.
The blue ellipse for Mahalanobis distance 
takes the correlation into account, so point "B" has a greater distance from the mean.

Mathematically, Euclidean (squared) distance for $p$ variables is just a generalization of
the square of a univariate standardized ($z$) score

$$
D^2 (\mathbf{y}) = (\mathbf{y} - \bar{\mathbf{y}})^T S^{-1} (\mathbf{y} - \bar{\mathbf{y}})
$$

For two variables, $x$ and $y$, the remarkable properties of the data ellipse are illustrated in @fig-galton-ellipse-r.

* The ellipses have the mean vector $(\bar{x}, \bar{y})$ as their center.

* The lengths of arms of the central cross show the standard deviations of the variables, which correspond to the shadows of the ellipse covering 40\% of the data. These are the bivariate analogs of 
the standard intervals $\bar{x} \pm 1 s_x$ and $\bar{y} \pm 1 s_y$.

* More generally, shadows (projections) on the coordinate axes, or any linear combination of them,
give any standard interval, 
  $\bar{x} \pm k s_x$ and $\bar{y} \pm k s_y$.
  Those with $k=1, 1.5, 2.45$, have
  bivariate coverage 40%, 68% and 95%, corresponding to these quantiles of the $\chi^2$ distribution
  with 2 degrees of freedom, i.e., 
  $\chi^2_2 (.40) \approx 1^2$, 
  $\chi^2_2 (.68) \approx 1.5^2$, and
  $\chi^2_2 (.95) \approx 2.45$.
  <!-- and univariate coverage 68\%, 87\% and 98.6\% respectively. -->

* The regression line predicting $y$ from $x$ goes through the points where the ellipses have vertical tangents. The _other_ regression line, predicting $x$ from $y$ goes through the points of horizontal
tangency.

* The correlation $r(x, y)$ is the ratio of the vertical segment from the mean of $y$ to the regression line to the vertical segment going to the top of the ellipse.


```{r}
#| label: fig-galton-ellipse-r
#| echo: false
#| fig-align: center
#| out-width: "80%"
#| fig-cap: "Sunflower plot of Galton's data on heights of parents and their children (in.), with
#|   40%, 68% and 95% data ellipses and the regression lines of $y$ on $x$ (black) and
#|   $x$ on $y$ (grey)."
knitr::include_graphics("images/galton-ellipse-r.jpg")
```
